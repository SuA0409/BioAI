{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cb14f7c",
   "metadata": {},
   "source": [
    "### Installation & Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb4c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdkit in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2025.3.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rdkit) (2.2.6)\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rdkit) (11.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install rdkit\n",
    "!pip install xgboost\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d3303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors, Lipinski\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost.callback import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e21063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost version: 3.0.3\n",
      "scikit-learn version: 1.7.1\n",
      "optuna version: 4.4.0\n"
     ]
    }
   ],
   "source": [
    "# version check\n",
    "import xgboost\n",
    "import sklearn\n",
    "import optuna\n",
    "\n",
    "print(\"xgboost version:\", xgboost.__version__)\n",
    "print(\"scikit-learn version:\", sklearn.__version__)\n",
    "print(\"optuna version:\", optuna.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00138def",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'NBITS': 2048,\n",
    "    'SEED': 42\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(CFG['SEED'])\n",
    "\n",
    "# SMILES 데이터를 분자 지문으로 변환\n",
    "def smiles_to_fingerprint(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=CFG['NBITS'])\n",
    "        return np.array(fp)\n",
    "    else:\n",
    "        return np.zeros((CFG['NBITS'],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a55359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IC50_to_pIC50(ic50_nM):\n",
    "    ic50_nM = np.clip(ic50_nM, 1e-10, None)\n",
    "    return 9 - np.log10(ic50_nM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a68d3cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pIC50_to_IC50(pIC50):\n",
    "    return 10 ** (9 - pIC50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece4d0ad",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e50e128",
   "metadata": {},
   "outputs": [],
   "source": [
    "IC50_dataset = pd.read_csv(\"C:/Users/user/Desktop/dacon_drug_development/IC50_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfda2f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:52] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:53] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n",
      "[08:07:55] DEPRECATION WARNING: please use MorganGenerator\n"
     ]
    }
   ],
   "source": [
    "IC50_dataset['Fingerprint'] = IC50_dataset['smiles'].apply(smiles_to_fingerprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f802df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(IC50_dataset['Fingerprint'].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03986cec",
   "metadata": {},
   "source": [
    "### Molecular Descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c17e5a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    f = {}\n",
    "    # 1. 화학기 존재 여부\n",
    "    # Tetrazole ring\n",
    "    tetrazole_smarts = ['c1nn[n+](n1)[O-]', 'c1[nH]nnn1']\n",
    "    f['has_tetrazole'] = any(mol.HasSubstructMatch(Chem.MolFromSmarts(s)) for s in tetrazole_smarts)\n",
    "    # Triazole ring\n",
    "    f['has_triazole'] = mol.HasSubstructMatch(Chem.MolFromSmarts('c1nnc(n1)'))\n",
    "    # Sulfoxide group\n",
    "    f['has_sulfoxide'] = mol.HasSubstructMatch(Chem.MolFromSmarts('S(=O)(C)'))\n",
    "    # Amide carbonyl\n",
    "    amide_smarts = ['C(=O)N', 'NC(=O)']\n",
    "    f['has_amide'] = any(mol.HasSubstructMatch(Chem.MolFromSmarts(s)) for s in amide_smarts)\n",
    "    # Sulfonamide group\n",
    "    f['has_sulfonamide'] = mol.HasSubstructMatch(Chem.MolFromSmarts('S(=O)(=O)N'))\n",
    "    \n",
    "    # 2. 분자량\n",
    "    mw = Descriptors.MolWt(mol)\n",
    "    f['mw'] = mw\n",
    "    f['mw_300_500'] = 300<=mw<=500\n",
    "    \n",
    "    # 3. logP\n",
    "    logp = Descriptors.MolLogP(mol)\n",
    "    f['logP'] = logp\n",
    "    f['logP_2_4'] = 2<=logp<=4\n",
    "    \n",
    "    # 4. TPSA\n",
    "    tpsa = Descriptors.TPSA(mol)\n",
    "    f['TPSA'] = tpsa\n",
    "    f['TPSA_60_120'] = 60<=tpsa<=120\n",
    "    \n",
    "    # 5. rotatable bonds (IC50 값 높임_bad)\n",
    "    rot = Lipinski.NumRotatableBonds(mol)\n",
    "    f['rotatable'] = rot\n",
    "    f['rot_gt7'] = rot>7\n",
    "\n",
    "    # 6. ring (+aromatic)\n",
    "    # ring 2개 이상\n",
    "    num_rings = mol.GetRingInfo().NumRings()\n",
    "    f['num_rings'] = num_rings\n",
    "    f['ring_count_ge_2'] = num_rings >= 2\n",
    "    # aromatic ring 존재 여부\n",
    "    ssr = Chem.GetSymmSSSR(mol)\n",
    "    aromatic_ring = any(all(mol.GetAtomWithIdx(idx).GetIsAromatic() for idx in ring) for ring in ssr)\n",
    "    f['has_aromatic_ring'] = aromatic_ring\n",
    "    # Ring 2개 이상 + 그 중 적어도 하나 aromatic인가?\n",
    "    f['ring_ge2_and_aromatic'] = f['ring_count_ge_2'] and f['has_aromatic_ring']\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "969a3592",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame([descriptors(s) for s in IC50_dataset['smiles']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07f826c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = pd.concat([IC50_dataset, features_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0a063c",
   "metadata": {},
   "source": [
    "### Train/Validation data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e64c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost에 넣으려면, Fingerprint를 실제 숫자 벡터 컬럼으로 풀어줘야 함.\n",
    "# 예를 들어, [0, 1, 0, 1] → fp_0=0, fp_1=1, fp_2=0, fp_3=1 이렇게 컬럼별 숫자로 변환.\n",
    "\n",
    "# 1. Fingerprint 컬럼을 여러 개 숫자 컬럼으로 변환\n",
    "fp_df = pd.DataFrame(final_dataset['Fingerprint'].tolist(), index=final_dataset.index)\n",
    "\n",
    "# 2. 컬럼 이름 부여 (fp_0, fp_1, ...)\n",
    "fp_df.columns = [f'fp_{i}' for i in range(fp_df.shape[1])]\n",
    "\n",
    "# 3. 기존 데이터에서 Fingerprint 컬럼 제거 후 합치기\n",
    "final_dataset = pd.concat(\n",
    "    [final_dataset.drop(columns=['Fingerprint']), fp_df],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b340ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X (features) and y (target)\n",
    "X = final_dataset.drop(['smiles', 'IC50_nM', 'pIC50'], axis=1)\n",
    "y = final_dataset['pIC50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77fff7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490300e7",
   "metadata": {},
   "source": [
    "### Building XGBRegressor model & Train/Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41609ffd",
   "metadata": {},
   "source": [
    "#### 하이퍼파라미터 수정X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf17e7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 1.1715\n",
      "Validation RMSE: 1.6037\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build and train the model\n",
    "model = XGBRegressor(\n",
    "    n_estimators=100, \n",
    "    random_state=42, \n",
    "    gamma=0,\n",
    "    max_depth=6,\n",
    "    reg_alpha=0,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    eval_metric='rmse'\n",
    "    )\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# 모델 학습 (validation 데이터로 평가하며 학습 로그 저장)\n",
    "eval_set = [(X_train, y_train), (X_val, y_val)]\n",
    "model.fit(X_train, y_train, eval_set=eval_set, verbose=False)\n",
    "\n",
    "# 4. Train / Validation 예측 및 RMSE 계산\n",
    "y_tr_pred = model.predict(X_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "rmse_train = mean_squared_error(y_train, y_tr_pred)**0.5\n",
    "rmse_val = mean_squared_error(y_val, y_val_pred)**0.5\n",
    "\n",
    "print(f\"Train RMSE: {rmse_train:.4f}\")\n",
    "print(f\"Validation RMSE: {rmse_val:.4f}\")\n",
    "\n",
    "# 학습 곡선 시각화 (학습 중 eval_metric 변화)\n",
    "results = model.evals_result()\n",
    "# print(results)\n",
    "# {'validation_0': OrderedDict({'rmse': [1.6757005114492605, 1.6282027337926461, ... 1.204247449411131]}), \n",
    "#  'validation_1': OrderedDict({'rmse': [1.6871148585793638, 1.6656733565849058, ... 1.7407150872811847]})}\n",
    "epochs = len(results['validation_0']['rmse'])\n",
    "x_axis = range(epochs)\n",
    "\n",
    "plt.plot(x_axis, results['validation_0']['rmse'], label='Train RMSE')\n",
    "plt.plot(x_axis, results['validation_1']['rmse'], label='Validation RMSE')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('XGBRegressor Learning Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3063c2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.630995   7.82085    7.506882   8.615394   7.7438354  7.8721137\n",
      "  6.04543    6.873217   8.189926   6.873217   7.7907176  9.001693\n",
      "  8.676523   7.836693   9.961205   7.515553   6.873217   8.236496\n",
      "  7.8032436  6.924535   8.721891   6.7017403  6.873217   8.052856\n",
      "  9.306874   8.124849   8.164332   6.5087996  6.873217   6.873217\n",
      "  6.873217   7.8445826  9.10404    7.411709   7.184741   7.8777947\n",
      "  9.306571   6.2808824  7.950636   8.234507   7.4467726  6.873217\n",
      " 10.495907   8.727929   9.078336   7.817878   8.303316   9.758623\n",
      "  8.197908   7.9128985  7.7443523  8.258657   5.749247   7.559815\n",
      "  6.928156   7.317553   6.821294   7.7951813  9.217065   6.8171477\n",
      "  7.755073   9.306874   6.109971   9.591785   7.2826123  7.724551\n",
      "  8.615394   7.657      7.925459   7.938434   6.873217   8.6900425\n",
      "  6.873217   8.164332   8.149224   7.2438927  7.6294117  8.958563\n",
      "  7.8427386  7.6862116  9.3929205  7.521518   7.808702   8.822137\n",
      "  7.655701   6.20937    7.8709755  8.236496   7.900044   6.873217\n",
      "  7.411709   7.2929587  8.924377   7.8300953  9.098518   6.873217\n",
      "  9.758623   7.791282   8.239538  10.265243   7.3251295  8.879787\n",
      "  8.384593   8.705896   8.708142   8.191123   6.435238   7.964128\n",
      "  8.239538   9.923297   5.967349   7.6592593  7.925459   6.873217\n",
      "  9.465406   7.9479423  7.670591   9.306874   6.873217   6.0043283\n",
      "  6.914953   6.873217   7.6739826  7.8476987  6.497597   6.265688\n",
      "  7.1857843  7.648053   8.621447   7.030608   9.011415   5.8338995\n",
      "  6.826366   8.708142   7.712294   7.3403907  7.854981   8.8312\n",
      "  7.4912853  7.806356   8.177688   7.989949   7.317553   6.712896\n",
      "  9.442559   8.384593   7.9133463  7.648053   8.260859   7.5921984\n",
      "  8.052856   7.888662   6.873217   7.8073115  8.501857   6.275231\n",
      "  8.888471   8.045023   6.8710513  9.362533   7.895577   6.960509\n",
      "  7.7048836  7.88268    6.873217   7.553535   8.164332   8.787635\n",
      "  8.72249    7.651004   7.889588   6.873217   7.8710046  7.7303944\n",
      "  7.9090853  8.346491   7.7306347  7.37568    7.925459   7.091893\n",
      "  6.7017403  7.6783485  5.6767325  7.616917   9.375614   7.8432007\n",
      "  9.10404    7.968258   7.806356   6.873217   7.8032436  9.70776\n",
      "  6.04543    7.8740673 10.265243  10.265243   5.386019   7.9408817\n",
      "  9.329916   6.3209405  7.868506   5.73781    6.281827   8.687819\n",
      "  7.7765245  6.1242003  6.7237244  5.1900654  7.9011827  7.906078\n",
      "  7.7567134  6.873217   6.0043283  7.273542  11.357731   9.465406\n",
      "  7.8022013  9.558624   6.873217   6.873217   8.705896   5.741214\n",
      "  8.0544615  7.837313   7.8709755  8.164332   7.7991614  8.149224\n",
      "  8.409779   5.730201   9.098518   7.6527224  7.7398543  9.096278\n",
      "  9.397967   7.906078   6.435238   7.906078  10.447776   9.266654\n",
      " 11.36784    7.583256   7.7659473  8.191123   7.4774365  6.1629987\n",
      "  7.855445   7.777459   7.7537766  7.810005   8.451492   8.863847\n",
      "  8.309351   9.306571   8.303316   6.2637844  7.936753   7.878349\n",
      "  7.9343357  7.8410897  7.9323587  7.973739   7.3462963  8.0129385\n",
      "  7.338211  11.55298    6.04543    9.33811    8.621447  11.635744\n",
      "  6.873217   7.8965507  7.080519  11.346349   8.384593   8.371249\n",
      "  7.839137   7.261616   7.9854274  6.873217   8.045505   8.816482\n",
      "  7.309058  10.02638    6.873217   8.551602  10.050162   6.873217\n",
      "  7.5269547  8.535699   6.211386   8.644792   6.4180713  6.873217\n",
      "  8.191123   7.754055   7.756179   8.160959   5.441179   7.7132893\n",
      "  7.9090853  8.514757   5.938905   7.8724384  7.070649   7.6294117\n",
      "  7.862935   7.832122   6.882277   9.078336   6.873217   7.8313227\n",
      "  6.873217   8.283079   7.1744294  7.724644   9.627268   6.873217\n",
      "  8.410944   6.873217   7.7927556  7.8740673 10.050162   7.865508\n",
      "  6.4180713 10.463861   8.954588   9.759412   9.591785   9.170508\n",
      "  7.1610417  7.878349   6.873217   7.77045    7.863636   8.829555\n",
      "  8.927147   7.8202715  7.850335   7.8386483  9.8671465 10.392753\n",
      "  9.523242   5.008361  10.050162   6.2034855  8.888471   9.457137\n",
      "  7.3951764  8.909145   7.9323587  9.33811    7.0389857  7.90847\n",
      "  7.8312855  7.813124   6.873217   8.164332   8.744671   6.873217\n",
      "  8.93322   11.50642    8.914154   8.712529   8.177688   7.906078\n",
      "  5.671304   7.8293347  9.428882   8.135833   8.177688   7.4274473\n",
      "  7.8721137  7.829799   8.753333   7.743483   6.6953716  8.514757\n",
      "  7.521518   7.4997187  7.932332   9.3929205  7.315019   8.813249\n",
      "  8.197908   7.906078   5.1900654  7.7735314  6.873217   8.596813\n",
      "  7.7220726  6.873217   7.353148   9.716659   8.501857   7.919611\n",
      "  7.795238   7.8526692  8.80387    7.7132893  9.759412   6.628894\n",
      "  6.361653   6.520786   8.741494   7.9043846  6.873217  10.6767025\n",
      "  8.087207   9.241822   6.873217   9.657479   6.4639244  8.164332\n",
      "  5.967248   8.117893   8.829555   7.8002872  7.788506   6.873217\n",
      "  7.832492   7.474916   7.7438354  9.260512   6.8710513  6.924535\n",
      "  7.949083  11.622378   9.567676   6.873217   6.873217   7.88268\n",
      "  9.163346   6.956368   7.5007124  8.93322    7.8134766  7.8781753\n",
      "  8.728918   7.2207108  8.93322    6.873217   7.8022013  7.907029\n",
      "  7.169461   7.74785    7.868902   7.82085    7.907442   9.626944\n",
      "  6.873217   7.968258   8.311439   7.873822   4.8464074  8.57691\n",
      "  7.791282  10.447776   7.8270955  7.82817    8.3351555  6.873217\n",
      "  6.661044   7.4885716  6.8450437  5.0143447  7.7270203  7.2804914\n",
      "  8.692114   7.1610417  6.873217   8.177688   7.724292   9.089608\n",
      "  5.6767325  7.7585316  8.940396   8.164332   5.28398    8.933614\n",
      "  6.7267447  6.873217  10.07988    7.9657235  8.024653  10.265267\n",
      "  8.258657  11.462706   5.4534693  7.7734137  6.1227818  7.9199867\n",
      "  8.514757   7.810005   7.648833   9.306874   7.2804914  7.378861\n",
      "  7.6811576  7.885625   7.892913   8.353863   9.456891   7.6801977\n",
      "  8.724058   7.7002177  7.642199   6.873217   9.408658   8.338228\n",
      "  7.8293347  8.501857   7.859975   6.0954633  7.6312537  9.397967\n",
      "  6.873217   6.873217   9.759412   5.4649425  9.045982   7.6801977\n",
      "  8.676523   9.660727   7.7325344  7.863239   8.676523   7.7316265\n",
      "  7.546403   8.905948   7.774124   7.718636   7.339643   6.873217\n",
      "  8.932633   7.476678   8.63627    7.850335   7.6628647  8.914154\n",
      "  6.873217   7.8655424  9.3929205  7.7002177  8.017235   7.273542\n",
      "  8.191123   7.813124   7.798597   9.499588   6.914953   7.5749974]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_val)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4caeb6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Mean Squared Error: 2.57\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_val, predictions)\n",
    "print(f\"Model Mean Squared Error: {mse:.2f}\")\n",
    "# 0에 가까울수록 성능 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7e2e77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1292767324754691"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 성능평가\n",
    "model.score(X_val, y_val)\n",
    "# 1에 가까울수록 성능 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d39beef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_tetrazole: 0.0000\n",
      "has_triazole: 0.0007\n",
      "has_sulfoxide: 0.0004\n",
      "has_amide: 0.0004\n",
      "has_sulfonamide: 0.0011\n",
      "mw: 0.0008\n",
      "mw_300_500: 0.0005\n",
      "logP: 0.0006\n",
      "logP_2_4: 0.0010\n",
      "TPSA: 0.0009\n",
      "TPSA_60_120: 0.0016\n",
      "rotatable: 0.0014\n",
      "rot_gt7: 0.0000\n",
      "num_rings: 0.0012\n",
      "ring_count_ge_2: 0.0000\n",
      "has_aromatic_ring: 0.0000\n",
      "ring_ge2_and_aromatic: 0.0000\n",
      "fp_0: 0.0000\n",
      "fp_1: 0.0012\n",
      "fp_2: 0.0007\n",
      "fp_3: 0.0000\n",
      "fp_4: 0.0000\n",
      "fp_5: 0.0007\n",
      "fp_6: 0.0000\n",
      "fp_7: 0.0000\n",
      "fp_8: 0.0007\n",
      "fp_9: 0.0009\n",
      "fp_10: 0.0036\n",
      "fp_11: 0.0007\n",
      "fp_12: 0.0000\n",
      "fp_13: 0.0000\n",
      "fp_14: 0.0006\n",
      "fp_15: 0.0000\n",
      "fp_16: 0.0000\n",
      "fp_17: 0.0000\n",
      "fp_18: 0.0000\n",
      "fp_19: 0.0000\n",
      "fp_20: 0.0022\n",
      "fp_21: 0.0000\n",
      "fp_22: 0.0000\n",
      "fp_23: 0.0000\n",
      "fp_24: 0.0000\n",
      "fp_25: 0.0000\n",
      "fp_26: 0.0007\n",
      "fp_27: 0.0000\n",
      "fp_28: 0.0000\n",
      "fp_29: 0.0004\n",
      "fp_30: 0.0000\n",
      "fp_31: 0.0000\n",
      "fp_32: 0.0000\n",
      "fp_33: 0.0001\n",
      "fp_34: 0.0000\n",
      "fp_35: 0.0000\n",
      "fp_36: 0.0000\n",
      "fp_37: 0.0000\n",
      "fp_38: 0.0000\n",
      "fp_39: 0.0000\n",
      "fp_40: 0.0004\n",
      "fp_41: 0.0000\n",
      "fp_42: 0.0000\n",
      "fp_43: 0.0004\n",
      "fp_44: 0.0000\n",
      "fp_45: 0.0007\n",
      "fp_46: 0.0014\n",
      "fp_47: 0.0000\n",
      "fp_48: 0.0000\n",
      "fp_49: 0.0000\n",
      "fp_50: 0.0017\n",
      "fp_51: 0.0000\n",
      "fp_52: 0.0015\n",
      "fp_53: 0.0000\n",
      "fp_54: 0.0053\n",
      "fp_55: 0.0000\n",
      "fp_56: 0.0009\n",
      "fp_57: 0.0039\n",
      "fp_58: 0.0013\n",
      "fp_59: 0.0000\n",
      "fp_60: 0.0000\n",
      "fp_61: 0.0011\n",
      "fp_62: 0.0000\n",
      "fp_63: 0.0000\n",
      "fp_64: 0.0004\n",
      "fp_65: 0.0010\n",
      "fp_66: 0.0027\n",
      "fp_67: 0.0021\n",
      "fp_68: 0.0000\n",
      "fp_69: 0.0000\n",
      "fp_70: 0.0000\n",
      "fp_71: 0.0000\n",
      "fp_72: 0.0000\n",
      "fp_73: 0.0000\n",
      "fp_74: 0.0013\n",
      "fp_75: 0.0000\n",
      "fp_76: 0.0000\n",
      "fp_77: 0.0006\n",
      "fp_78: 0.0000\n",
      "fp_79: 0.0013\n",
      "fp_80: 0.0005\n",
      "fp_81: 0.0011\n",
      "fp_82: 0.0000\n",
      "fp_83: 0.0000\n",
      "fp_84: 0.0000\n",
      "fp_85: 0.0000\n",
      "fp_86: 0.0000\n",
      "fp_87: 0.0000\n",
      "fp_88: 0.0000\n",
      "fp_89: 0.0000\n",
      "fp_90: 0.0009\n",
      "fp_91: 0.0000\n",
      "fp_92: 0.0000\n",
      "fp_93: 0.0010\n",
      "fp_94: 0.0001\n",
      "fp_95: 0.0008\n",
      "fp_96: 0.0000\n",
      "fp_97: 0.0000\n",
      "fp_98: 0.0000\n",
      "fp_99: 0.0000\n",
      "fp_100: 0.0000\n",
      "fp_101: 0.0000\n",
      "fp_102: 0.0001\n",
      "fp_103: 0.0000\n",
      "fp_104: 0.0000\n",
      "fp_105: 0.0000\n",
      "fp_106: 0.0000\n",
      "fp_107: 0.0000\n",
      "fp_108: 0.0000\n",
      "fp_109: 0.0000\n",
      "fp_110: 0.0036\n",
      "fp_111: 0.0000\n",
      "fp_112: 0.0000\n",
      "fp_113: 0.0000\n",
      "fp_114: 0.0012\n",
      "fp_115: 0.0003\n",
      "fp_116: 0.0010\n",
      "fp_117: 0.0000\n",
      "fp_118: 0.0009\n",
      "fp_119: 0.0000\n",
      "fp_120: 0.0000\n",
      "fp_121: 0.0000\n",
      "fp_122: 0.0008\n",
      "fp_123: 0.0000\n",
      "fp_124: 0.0000\n",
      "fp_125: 0.0000\n",
      "fp_126: 0.0000\n",
      "fp_127: 0.0000\n",
      "fp_128: 0.0000\n",
      "fp_129: 0.0000\n",
      "fp_130: 0.0000\n",
      "fp_131: 0.0000\n",
      "fp_132: 0.0000\n",
      "fp_133: 0.0000\n",
      "fp_134: 0.0000\n",
      "fp_135: 0.0000\n",
      "fp_136: 0.0029\n",
      "fp_137: 0.0000\n",
      "fp_138: 0.0015\n",
      "fp_139: 0.0011\n",
      "fp_140: 0.0023\n",
      "fp_141: 0.0000\n",
      "fp_142: 0.0000\n",
      "fp_143: 0.0000\n",
      "fp_144: 0.0010\n",
      "fp_145: 0.0007\n",
      "fp_146: 0.0000\n",
      "fp_147: 0.0010\n",
      "fp_148: 0.0000\n",
      "fp_149: 0.0000\n",
      "fp_150: 0.0000\n",
      "fp_151: 0.0000\n",
      "fp_152: 0.0000\n",
      "fp_153: 0.0000\n",
      "fp_154: 0.0004\n",
      "fp_155: 0.0000\n",
      "fp_156: 0.0016\n",
      "fp_157: 0.0007\n",
      "fp_158: 0.0000\n",
      "fp_159: 0.0000\n",
      "fp_160: 0.0000\n",
      "fp_161: 0.0000\n",
      "fp_162: 0.0028\n",
      "fp_163: 0.0000\n",
      "fp_164: 0.0000\n",
      "fp_165: 0.0002\n",
      "fp_166: 0.0008\n",
      "fp_167: 0.0000\n",
      "fp_168: 0.0005\n",
      "fp_169: 0.0013\n",
      "fp_170: 0.0000\n",
      "fp_171: 0.0000\n",
      "fp_172: 0.0000\n",
      "fp_173: 0.0000\n",
      "fp_174: 0.0000\n",
      "fp_175: 0.0000\n",
      "fp_176: 0.0000\n",
      "fp_177: 0.0000\n",
      "fp_178: 0.0000\n",
      "fp_179: 0.0000\n",
      "fp_180: 0.0000\n",
      "fp_181: 0.0000\n",
      "fp_182: 0.0000\n",
      "fp_183: 0.0000\n",
      "fp_184: 0.0015\n",
      "fp_185: 0.0000\n",
      "fp_186: 0.0002\n",
      "fp_187: 0.0000\n",
      "fp_188: 0.0000\n",
      "fp_189: 0.0000\n",
      "fp_190: 0.0000\n",
      "fp_191: 0.0009\n",
      "fp_192: 0.0000\n",
      "fp_193: 0.0000\n",
      "fp_194: 0.0000\n",
      "fp_195: 0.0000\n",
      "fp_196: 0.0002\n",
      "fp_197: 0.0000\n",
      "fp_198: 0.0000\n",
      "fp_199: 0.0000\n",
      "fp_200: 0.0000\n",
      "fp_201: 0.0000\n",
      "fp_202: 0.0013\n",
      "fp_203: 0.0025\n",
      "fp_204: 0.0005\n",
      "fp_205: 0.0000\n",
      "fp_206: 0.0001\n",
      "fp_207: 0.0000\n",
      "fp_208: 0.0000\n",
      "fp_209: 0.0000\n",
      "fp_210: 0.0000\n",
      "fp_211: 0.0000\n",
      "fp_212: 0.0000\n",
      "fp_213: 0.0000\n",
      "fp_214: 0.0000\n",
      "fp_215: 0.0019\n",
      "fp_216: 0.0000\n",
      "fp_217: 0.0000\n",
      "fp_218: 0.0000\n",
      "fp_219: 0.0000\n",
      "fp_220: 0.0000\n",
      "fp_221: 0.0000\n",
      "fp_222: 0.0007\n",
      "fp_223: 0.0012\n",
      "fp_224: 0.0000\n",
      "fp_225: 0.0000\n",
      "fp_226: 0.0015\n",
      "fp_227: 0.0000\n",
      "fp_228: 0.0000\n",
      "fp_229: 0.0000\n",
      "fp_230: 0.0001\n",
      "fp_231: 0.0000\n",
      "fp_232: 0.0000\n",
      "fp_233: 0.0010\n",
      "fp_234: 0.0000\n",
      "fp_235: 0.0018\n",
      "fp_236: 0.0000\n",
      "fp_237: 0.0007\n",
      "fp_238: 0.0019\n",
      "fp_239: 0.0000\n",
      "fp_240: 0.0000\n",
      "fp_241: 0.0015\n",
      "fp_242: 0.0000\n",
      "fp_243: 0.0000\n",
      "fp_244: 0.0000\n",
      "fp_245: 0.0000\n",
      "fp_246: 0.0009\n",
      "fp_247: 0.0000\n",
      "fp_248: 0.0000\n",
      "fp_249: 0.0011\n",
      "fp_250: 0.0009\n",
      "fp_251: 0.0000\n",
      "fp_252: 0.0009\n",
      "fp_253: 0.0000\n",
      "fp_254: 0.0000\n",
      "fp_255: 0.0000\n",
      "fp_256: 0.0010\n",
      "fp_257: 0.0011\n",
      "fp_258: 0.0000\n",
      "fp_259: 0.0000\n",
      "fp_260: 0.0000\n",
      "fp_261: 0.0000\n",
      "fp_262: 0.0000\n",
      "fp_263: 0.0000\n",
      "fp_264: 0.0008\n",
      "fp_265: 0.0000\n",
      "fp_266: 0.0000\n",
      "fp_267: 0.0000\n",
      "fp_268: 0.0000\n",
      "fp_269: 0.0000\n",
      "fp_270: 0.0012\n",
      "fp_271: 0.0000\n",
      "fp_272: 0.0000\n",
      "fp_273: 0.0000\n",
      "fp_274: 0.0000\n",
      "fp_275: 0.0000\n",
      "fp_276: 0.0000\n",
      "fp_277: 0.0000\n",
      "fp_278: 0.0000\n",
      "fp_279: 0.0000\n",
      "fp_280: 0.0000\n",
      "fp_281: 0.0014\n",
      "fp_282: 0.0000\n",
      "fp_283: 0.0054\n",
      "fp_284: 0.0000\n",
      "fp_285: 0.0000\n",
      "fp_286: 0.0000\n",
      "fp_287: 0.0000\n",
      "fp_288: 0.0000\n",
      "fp_289: 0.0005\n",
      "fp_290: 0.0000\n",
      "fp_291: 0.0000\n",
      "fp_292: 0.0000\n",
      "fp_293: 0.0801\n",
      "fp_294: 0.0009\n",
      "fp_295: 0.0000\n",
      "fp_296: 0.0000\n",
      "fp_297: 0.0000\n",
      "fp_298: 0.0000\n",
      "fp_299: 0.0000\n",
      "fp_300: 0.0000\n",
      "fp_301: 0.0000\n",
      "fp_302: 0.0012\n",
      "fp_303: 0.0000\n",
      "fp_304: 0.0000\n",
      "fp_305: 0.0000\n",
      "fp_306: 0.0000\n",
      "fp_307: 0.0007\n",
      "fp_308: 0.0000\n",
      "fp_309: 0.0000\n",
      "fp_310: 0.0008\n",
      "fp_311: 0.0000\n",
      "fp_312: 0.0000\n",
      "fp_313: 0.0000\n",
      "fp_314: 0.0015\n",
      "fp_315: 0.0015\n",
      "fp_316: 0.0006\n",
      "fp_317: 0.0002\n",
      "fp_318: 0.0000\n",
      "fp_319: 0.0007\n",
      "fp_320: 0.0000\n",
      "fp_321: 0.0000\n",
      "fp_322: 0.0008\n",
      "fp_323: 0.0040\n",
      "fp_324: 0.0000\n",
      "fp_325: 0.0000\n",
      "fp_326: 0.0113\n",
      "fp_327: 0.0003\n",
      "fp_328: 0.0000\n",
      "fp_329: 0.0002\n",
      "fp_330: 0.0000\n",
      "fp_331: 0.0000\n",
      "fp_332: 0.0000\n",
      "fp_333: 0.0000\n",
      "fp_334: 0.0000\n",
      "fp_335: 0.0000\n",
      "fp_336: 0.0000\n",
      "fp_337: 0.0000\n",
      "fp_338: 0.0006\n",
      "fp_339: 0.0000\n",
      "fp_340: 0.0000\n",
      "fp_341: 0.0000\n",
      "fp_342: 0.0000\n",
      "fp_343: 0.0015\n",
      "fp_344: 0.0057\n",
      "fp_345: 0.0007\n",
      "fp_346: 0.0000\n",
      "fp_347: 0.0012\n",
      "fp_348: 0.0000\n",
      "fp_349: 0.0000\n",
      "fp_350: 0.0000\n",
      "fp_351: 0.0000\n",
      "fp_352: 0.0025\n",
      "fp_353: 0.0002\n",
      "fp_354: 0.0000\n",
      "fp_355: 0.0000\n",
      "fp_356: 0.0000\n",
      "fp_357: 0.0013\n",
      "fp_358: 0.0000\n",
      "fp_359: 0.0000\n",
      "fp_360: 0.0000\n",
      "fp_361: 0.0013\n",
      "fp_362: 0.0000\n",
      "fp_363: 0.0000\n",
      "fp_364: 0.0011\n",
      "fp_365: 0.0000\n",
      "fp_366: 0.0000\n",
      "fp_367: 0.0000\n",
      "fp_368: 0.0000\n",
      "fp_369: 0.0000\n",
      "fp_370: 0.0000\n",
      "fp_371: 0.0000\n",
      "fp_372: 0.0000\n",
      "fp_373: 0.0000\n",
      "fp_374: 0.0000\n",
      "fp_375: 0.0000\n",
      "fp_376: 0.0000\n",
      "fp_377: 0.0000\n",
      "fp_378: 0.0004\n",
      "fp_379: 0.0020\n",
      "fp_380: 0.0000\n",
      "fp_381: 0.0013\n",
      "fp_382: 0.0015\n",
      "fp_383: 0.0001\n",
      "fp_384: 0.0023\n",
      "fp_385: 0.0000\n",
      "fp_386: 0.0000\n",
      "fp_387: 0.0037\n",
      "fp_388: 0.0000\n",
      "fp_389: 0.0090\n",
      "fp_390: 0.0000\n",
      "fp_391: 0.0002\n",
      "fp_392: 0.0000\n",
      "fp_393: 0.0000\n",
      "fp_394: 0.0007\n",
      "fp_395: 0.0007\n",
      "fp_396: 0.0000\n",
      "fp_397: 0.0000\n",
      "fp_398: 0.0000\n",
      "fp_399: 0.0000\n",
      "fp_400: 0.0000\n",
      "fp_401: 0.0011\n",
      "fp_402: 0.0000\n",
      "fp_403: 0.0000\n",
      "fp_404: 0.0000\n",
      "fp_405: 0.0000\n",
      "fp_406: 0.0000\n",
      "fp_407: 0.0012\n",
      "fp_408: 0.0000\n",
      "fp_409: 0.0000\n",
      "fp_410: 0.0000\n",
      "fp_411: 0.0000\n",
      "fp_412: 0.0016\n",
      "fp_413: 0.0000\n",
      "fp_414: 0.0000\n",
      "fp_415: 0.0000\n",
      "fp_416: 0.0000\n",
      "fp_417: 0.0000\n",
      "fp_418: 0.0000\n",
      "fp_419: 0.0000\n",
      "fp_420: 0.0000\n",
      "fp_421: 0.0000\n",
      "fp_422: 0.0035\n",
      "fp_423: 0.0000\n",
      "fp_424: 0.0000\n",
      "fp_425: 0.0000\n",
      "fp_426: 0.0012\n",
      "fp_427: 0.0007\n",
      "fp_428: 0.0000\n",
      "fp_429: 0.0015\n",
      "fp_430: 0.0000\n",
      "fp_431: 0.0000\n",
      "fp_432: 0.0000\n",
      "fp_433: 0.0000\n",
      "fp_434: 0.0000\n",
      "fp_435: 0.0000\n",
      "fp_436: 0.0000\n",
      "fp_437: 0.0008\n",
      "fp_438: 0.0000\n",
      "fp_439: 0.0000\n",
      "fp_440: 0.0000\n",
      "fp_441: 0.0004\n",
      "fp_442: 0.0009\n",
      "fp_443: 0.0000\n",
      "fp_444: 0.0000\n",
      "fp_445: 0.0121\n",
      "fp_446: 0.0000\n",
      "fp_447: 0.0000\n",
      "fp_448: 0.0005\n",
      "fp_449: 0.0000\n",
      "fp_450: 0.0007\n",
      "fp_451: 0.0012\n",
      "fp_452: 0.0000\n",
      "fp_453: 0.0000\n",
      "fp_454: 0.0016\n",
      "fp_455: 0.0000\n",
      "fp_456: 0.0000\n",
      "fp_457: 0.0000\n",
      "fp_458: 0.0017\n",
      "fp_459: 0.0000\n",
      "fp_460: 0.0000\n",
      "fp_461: 0.0012\n",
      "fp_462: 0.0000\n",
      "fp_463: 0.0011\n",
      "fp_464: 0.0031\n",
      "fp_465: 0.0000\n",
      "fp_466: 0.0000\n",
      "fp_467: 0.0000\n",
      "fp_468: 0.0000\n",
      "fp_469: 0.0000\n",
      "fp_470: 0.0000\n",
      "fp_471: 0.0000\n",
      "fp_472: 0.0000\n",
      "fp_473: 0.0000\n",
      "fp_474: 0.0001\n",
      "fp_475: 0.0010\n",
      "fp_476: 0.0000\n",
      "fp_477: 0.0000\n",
      "fp_478: 0.0000\n",
      "fp_479: 0.0000\n",
      "fp_480: 0.0000\n",
      "fp_481: 0.0000\n",
      "fp_482: 0.0000\n",
      "fp_483: 0.0000\n",
      "fp_484: 0.0000\n",
      "fp_485: 0.0003\n",
      "fp_486: 0.0007\n",
      "fp_487: 0.0000\n",
      "fp_488: 0.0000\n",
      "fp_489: 0.0000\n",
      "fp_490: 0.0000\n",
      "fp_491: 0.0000\n",
      "fp_492: 0.0000\n",
      "fp_493: 0.0004\n",
      "fp_494: 0.0000\n",
      "fp_495: 0.0000\n",
      "fp_496: 0.0012\n",
      "fp_497: 0.0000\n",
      "fp_498: 0.0000\n",
      "fp_499: 0.0000\n",
      "fp_500: 0.0000\n",
      "fp_501: 0.0000\n",
      "fp_502: 0.0000\n",
      "fp_503: 0.0000\n",
      "fp_504: 0.0014\n",
      "fp_505: 0.0000\n",
      "fp_506: 0.0000\n",
      "fp_507: 0.0000\n",
      "fp_508: 0.0000\n",
      "fp_509: 0.0000\n",
      "fp_510: 0.0000\n",
      "fp_511: 0.0000\n",
      "fp_512: 0.0000\n",
      "fp_513: 0.0000\n",
      "fp_514: 0.0000\n",
      "fp_515: 0.0000\n",
      "fp_516: 0.0000\n",
      "fp_517: 0.0000\n",
      "fp_518: 0.0309\n",
      "fp_519: 0.0000\n",
      "fp_520: 0.0000\n",
      "fp_521: 0.0000\n",
      "fp_522: 0.0000\n",
      "fp_523: 0.0003\n",
      "fp_524: 0.0000\n",
      "fp_525: 0.0024\n",
      "fp_526: 0.0007\n",
      "fp_527: 0.0000\n",
      "fp_528: 0.0000\n",
      "fp_529: 0.0000\n",
      "fp_530: 0.0007\n",
      "fp_531: 0.0000\n",
      "fp_532: 0.0000\n",
      "fp_533: 0.0000\n",
      "fp_534: 0.0000\n",
      "fp_535: 0.0000\n",
      "fp_536: 0.0000\n",
      "fp_537: 0.0000\n",
      "fp_538: 0.0000\n",
      "fp_539: 0.0009\n",
      "fp_540: 0.0000\n",
      "fp_541: 0.0012\n",
      "fp_542: 0.0000\n",
      "fp_543: 0.0000\n",
      "fp_544: 0.0000\n",
      "fp_545: 0.0000\n",
      "fp_546: 0.0000\n",
      "fp_547: 0.0000\n",
      "fp_548: 0.0000\n",
      "fp_549: 0.0029\n",
      "fp_550: 0.0000\n",
      "fp_551: 0.0000\n",
      "fp_552: 0.0030\n",
      "fp_553: 0.0000\n",
      "fp_554: 0.0000\n",
      "fp_555: 0.0000\n",
      "fp_556: 0.0000\n",
      "fp_557: 0.0000\n",
      "fp_558: 0.0000\n",
      "fp_559: 0.0000\n",
      "fp_560: 0.0000\n",
      "fp_561: 0.0007\n",
      "fp_562: 0.0010\n",
      "fp_563: 0.0000\n",
      "fp_564: 0.0021\n",
      "fp_565: 0.0011\n",
      "fp_566: 0.0000\n",
      "fp_567: 0.0000\n",
      "fp_568: 0.0000\n",
      "fp_569: 0.0001\n",
      "fp_570: 0.0012\n",
      "fp_571: 0.0025\n",
      "fp_572: 0.0000\n",
      "fp_573: 0.0021\n",
      "fp_574: 0.0000\n",
      "fp_575: 0.0011\n",
      "fp_576: 0.0000\n",
      "fp_577: 0.0000\n",
      "fp_578: 0.0000\n",
      "fp_579: 0.0000\n",
      "fp_580: 0.0025\n",
      "fp_581: 0.0000\n",
      "fp_582: 0.0000\n",
      "fp_583: 0.0000\n",
      "fp_584: 0.0000\n",
      "fp_585: 0.0000\n",
      "fp_586: 0.0022\n",
      "fp_587: 0.0019\n",
      "fp_588: 0.0000\n",
      "fp_589: 0.0000\n",
      "fp_590: 0.0000\n",
      "fp_591: 0.0000\n",
      "fp_592: 0.0008\n",
      "fp_593: 0.0000\n",
      "fp_594: 0.0000\n",
      "fp_595: 0.0000\n",
      "fp_596: 0.0000\n",
      "fp_597: 0.0013\n",
      "fp_598: 0.0003\n",
      "fp_599: 0.0003\n",
      "fp_600: 0.0021\n",
      "fp_601: 0.0000\n",
      "fp_602: 0.0000\n",
      "fp_603: 0.0000\n",
      "fp_604: 0.0000\n",
      "fp_605: 0.0000\n",
      "fp_606: 0.0000\n",
      "fp_607: 0.0000\n",
      "fp_608: 0.0020\n",
      "fp_609: 0.0007\n",
      "fp_610: 0.0000\n",
      "fp_611: 0.0000\n",
      "fp_612: 0.0000\n",
      "fp_613: 0.0017\n",
      "fp_614: 0.0000\n",
      "fp_615: 0.0012\n",
      "fp_616: 0.0000\n",
      "fp_617: 0.0010\n",
      "fp_618: 0.0014\n",
      "fp_619: 0.0000\n",
      "fp_620: 0.0000\n",
      "fp_621: 0.0000\n",
      "fp_622: 0.0000\n",
      "fp_623: 0.0000\n",
      "fp_624: 0.0000\n",
      "fp_625: 0.0000\n",
      "fp_626: 0.0000\n",
      "fp_627: 0.0000\n",
      "fp_628: 0.0084\n",
      "fp_629: 0.0000\n",
      "fp_630: 0.0000\n",
      "fp_631: 0.0000\n",
      "fp_632: 0.0000\n",
      "fp_633: 0.0000\n",
      "fp_634: 0.0000\n",
      "fp_635: 0.0000\n",
      "fp_636: 0.0000\n",
      "fp_637: 0.0000\n",
      "fp_638: 0.0000\n",
      "fp_639: 0.0000\n",
      "fp_640: 0.0000\n",
      "fp_641: 0.0000\n",
      "fp_642: 0.0000\n",
      "fp_643: 0.0000\n",
      "fp_644: 0.0000\n",
      "fp_645: 0.0000\n",
      "fp_646: 0.0000\n",
      "fp_647: 0.0016\n",
      "fp_648: 0.0000\n",
      "fp_649: 0.0000\n",
      "fp_650: 0.0000\n",
      "fp_651: 0.0000\n",
      "fp_652: 0.0008\n",
      "fp_653: 0.0000\n",
      "fp_654: 0.0000\n",
      "fp_655: 0.0000\n",
      "fp_656: 0.0012\n",
      "fp_657: 0.0013\n",
      "fp_658: 0.0000\n",
      "fp_659: 0.0000\n",
      "fp_660: 0.0000\n",
      "fp_661: 0.0000\n",
      "fp_662: 0.0000\n",
      "fp_663: 0.0000\n",
      "fp_664: 0.0010\n",
      "fp_665: 0.0000\n",
      "fp_666: 0.0013\n",
      "fp_667: 0.0000\n",
      "fp_668: 0.0008\n",
      "fp_669: 0.0000\n",
      "fp_670: 0.0000\n",
      "fp_671: 0.0005\n",
      "fp_672: 0.0012\n",
      "fp_673: 0.0000\n",
      "fp_674: 0.0000\n",
      "fp_675: 0.0000\n",
      "fp_676: 0.0000\n",
      "fp_677: 0.0000\n",
      "fp_678: 0.0013\n",
      "fp_679: 0.0010\n",
      "fp_680: 0.0008\n",
      "fp_681: 0.0000\n",
      "fp_682: 0.0007\n",
      "fp_683: 0.0000\n",
      "fp_684: 0.0010\n",
      "fp_685: 0.0000\n",
      "fp_686: 0.0000\n",
      "fp_687: 0.0000\n",
      "fp_688: 0.0000\n",
      "fp_689: 0.0000\n",
      "fp_690: 0.0000\n",
      "fp_691: 0.0014\n",
      "fp_692: 0.0010\n",
      "fp_693: 0.0000\n",
      "fp_694: 0.0000\n",
      "fp_695: 0.0075\n",
      "fp_696: 0.0000\n",
      "fp_697: 0.0000\n",
      "fp_698: 0.0000\n",
      "fp_699: 0.0004\n",
      "fp_700: 0.0000\n",
      "fp_701: 0.0000\n",
      "fp_702: 0.0000\n",
      "fp_703: 0.0000\n",
      "fp_704: 0.0000\n",
      "fp_705: 0.0000\n",
      "fp_706: 0.0000\n",
      "fp_707: 0.0000\n",
      "fp_708: 0.0000\n",
      "fp_709: 0.0000\n",
      "fp_710: 0.0000\n",
      "fp_711: 0.0000\n",
      "fp_712: 0.0000\n",
      "fp_713: 0.0000\n",
      "fp_714: 0.0007\n",
      "fp_715: 0.0012\n",
      "fp_716: 0.0010\n",
      "fp_717: 0.0022\n",
      "fp_718: 0.0000\n",
      "fp_719: 0.0000\n",
      "fp_720: 0.0000\n",
      "fp_721: 0.0000\n",
      "fp_722: 0.0000\n",
      "fp_723: 0.0015\n",
      "fp_724: 0.0000\n",
      "fp_725: 0.0000\n",
      "fp_726: 0.0013\n",
      "fp_727: 0.0000\n",
      "fp_728: 0.0003\n",
      "fp_729: 0.0000\n",
      "fp_730: 0.0000\n",
      "fp_731: 0.0000\n",
      "fp_732: 0.0016\n",
      "fp_733: 0.0000\n",
      "fp_734: 0.0024\n",
      "fp_735: 0.0000\n",
      "fp_736: 0.0009\n",
      "fp_737: 0.0000\n",
      "fp_738: 0.0000\n",
      "fp_739: 0.0024\n",
      "fp_740: 0.0000\n",
      "fp_741: 0.0000\n",
      "fp_742: 0.0000\n",
      "fp_743: 0.0000\n",
      "fp_744: 0.0000\n",
      "fp_745: 0.0000\n",
      "fp_746: 0.0000\n",
      "fp_747: 0.0000\n",
      "fp_748: 0.0000\n",
      "fp_749: 0.0000\n",
      "fp_750: 0.0014\n",
      "fp_751: 0.0000\n",
      "fp_752: 0.0000\n",
      "fp_753: 0.0000\n",
      "fp_754: 0.0000\n",
      "fp_755: 0.0020\n",
      "fp_756: 0.0000\n",
      "fp_757: 0.0000\n",
      "fp_758: 0.0000\n",
      "fp_759: 0.0000\n",
      "fp_760: 0.0000\n",
      "fp_761: 0.0000\n",
      "fp_762: 0.0000\n",
      "fp_763: 0.0000\n",
      "fp_764: 0.0000\n",
      "fp_765: 0.0000\n",
      "fp_766: 0.0010\n",
      "fp_767: 0.0000\n",
      "fp_768: 0.0000\n",
      "fp_769: 0.0000\n",
      "fp_770: 0.0027\n",
      "fp_771: 0.0000\n",
      "fp_772: 0.0000\n",
      "fp_773: 0.0000\n",
      "fp_774: 0.0000\n",
      "fp_775: 0.0000\n",
      "fp_776: 0.0000\n",
      "fp_777: 0.0000\n",
      "fp_778: 0.0000\n",
      "fp_779: 0.0000\n",
      "fp_780: 0.0000\n",
      "fp_781: 0.0000\n",
      "fp_782: 0.0000\n",
      "fp_783: 0.0000\n",
      "fp_784: 0.0000\n",
      "fp_785: 0.0000\n",
      "fp_786: 0.0000\n",
      "fp_787: 0.0006\n",
      "fp_788: 0.0000\n",
      "fp_789: 0.0000\n",
      "fp_790: 0.0000\n",
      "fp_791: 0.0000\n",
      "fp_792: 0.0000\n",
      "fp_793: 0.0000\n",
      "fp_794: 0.0000\n",
      "fp_795: 0.0000\n",
      "fp_796: 0.0000\n",
      "fp_797: 0.0000\n",
      "fp_798: 0.0023\n",
      "fp_799: 0.0000\n",
      "fp_800: 0.0000\n",
      "fp_801: 0.0000\n",
      "fp_802: 0.0014\n",
      "fp_803: 0.0000\n",
      "fp_804: 0.0000\n",
      "fp_805: 0.0000\n",
      "fp_806: 0.0000\n",
      "fp_807: 0.0000\n",
      "fp_808: 0.0000\n",
      "fp_809: 0.0000\n",
      "fp_810: 0.0000\n",
      "fp_811: 0.0000\n",
      "fp_812: 0.0000\n",
      "fp_813: 0.0000\n",
      "fp_814: 0.0000\n",
      "fp_815: 0.0000\n",
      "fp_816: 0.0000\n",
      "fp_817: 0.0000\n",
      "fp_818: 0.0000\n",
      "fp_819: 0.0071\n",
      "fp_820: 0.0000\n",
      "fp_821: 0.0000\n",
      "fp_822: 0.0000\n",
      "fp_823: 0.0000\n",
      "fp_824: 0.0000\n",
      "fp_825: 0.0000\n",
      "fp_826: 0.0000\n",
      "fp_827: 0.0000\n",
      "fp_828: 0.0016\n",
      "fp_829: 0.0218\n",
      "fp_830: 0.0000\n",
      "fp_831: 0.0000\n",
      "fp_832: 0.0000\n",
      "fp_833: 0.0000\n",
      "fp_834: 0.0000\n",
      "fp_835: 0.0000\n",
      "fp_836: 0.0000\n",
      "fp_837: 0.0000\n",
      "fp_838: 0.0000\n",
      "fp_839: 0.0000\n",
      "fp_840: 0.0000\n",
      "fp_841: 0.0061\n",
      "fp_842: 0.0000\n",
      "fp_843: 0.0004\n",
      "fp_844: 0.0000\n",
      "fp_845: 0.0000\n",
      "fp_846: 0.0000\n",
      "fp_847: 0.0000\n",
      "fp_848: 0.0000\n",
      "fp_849: 0.0000\n",
      "fp_850: 0.0000\n",
      "fp_851: 0.0000\n",
      "fp_852: 0.0000\n",
      "fp_853: 0.0009\n",
      "fp_854: 0.0000\n",
      "fp_855: 0.0026\n",
      "fp_856: 0.0000\n",
      "fp_857: 0.0000\n",
      "fp_858: 0.0000\n",
      "fp_859: 0.0000\n",
      "fp_860: 0.0000\n",
      "fp_861: 0.0000\n",
      "fp_862: 0.0000\n",
      "fp_863: 0.0000\n",
      "fp_864: 0.0012\n",
      "fp_865: 0.0000\n",
      "fp_866: 0.0000\n",
      "fp_867: 0.0000\n",
      "fp_868: 0.0000\n",
      "fp_869: 0.0000\n",
      "fp_870: 0.0000\n",
      "fp_871: 0.0000\n",
      "fp_872: 0.0000\n",
      "fp_873: 0.0000\n",
      "fp_874: 0.0000\n",
      "fp_875: 0.0005\n",
      "fp_876: 0.0000\n",
      "fp_877: 0.0000\n",
      "fp_878: 0.0015\n",
      "fp_879: 0.0093\n",
      "fp_880: 0.0000\n",
      "fp_881: 0.0010\n",
      "fp_882: 0.0000\n",
      "fp_883: 0.0000\n",
      "fp_884: 0.0000\n",
      "fp_885: 0.0010\n",
      "fp_886: 0.0000\n",
      "fp_887: 0.0000\n",
      "fp_888: 0.0000\n",
      "fp_889: 0.0000\n",
      "fp_890: 0.0004\n",
      "fp_891: 0.0000\n",
      "fp_892: 0.0000\n",
      "fp_893: 0.0012\n",
      "fp_894: 0.0000\n",
      "fp_895: 0.0000\n",
      "fp_896: 0.0008\n",
      "fp_897: 0.0000\n",
      "fp_898: 0.0033\n",
      "fp_899: 0.0000\n",
      "fp_900: 0.0000\n",
      "fp_901: 0.0000\n",
      "fp_902: 0.0000\n",
      "fp_903: 0.0000\n",
      "fp_904: 0.0000\n",
      "fp_905: 0.0000\n",
      "fp_906: 0.0000\n",
      "fp_907: 0.0000\n",
      "fp_908: 0.0000\n",
      "fp_909: 0.0005\n",
      "fp_910: 0.0000\n",
      "fp_911: 0.0000\n",
      "fp_912: 0.0000\n",
      "fp_913: 0.0000\n",
      "fp_914: 0.0000\n",
      "fp_915: 0.0000\n",
      "fp_916: 0.0000\n",
      "fp_917: 0.0000\n",
      "fp_918: 0.0000\n",
      "fp_919: 0.0000\n",
      "fp_920: 0.0000\n",
      "fp_921: 0.0000\n",
      "fp_922: 0.0000\n",
      "fp_923: 0.0000\n",
      "fp_924: 0.0000\n",
      "fp_925: 0.0000\n",
      "fp_926: 0.0005\n",
      "fp_927: 0.0000\n",
      "fp_928: 0.0000\n",
      "fp_929: 0.0000\n",
      "fp_930: 0.0010\n",
      "fp_931: 0.0000\n",
      "fp_932: 0.0004\n",
      "fp_933: 0.0000\n",
      "fp_934: 0.0011\n",
      "fp_935: 0.0007\n",
      "fp_936: 0.0000\n",
      "fp_937: 0.0000\n",
      "fp_938: 0.0000\n",
      "fp_939: 0.0000\n",
      "fp_940: 0.0000\n",
      "fp_941: 0.0000\n",
      "fp_942: 0.0000\n",
      "fp_943: 0.0000\n",
      "fp_944: 0.0000\n",
      "fp_945: 0.0010\n",
      "fp_946: 0.0000\n",
      "fp_947: 0.0000\n",
      "fp_948: 0.0000\n",
      "fp_949: 0.0000\n",
      "fp_950: 0.0041\n",
      "fp_951: 0.0000\n",
      "fp_952: 0.0000\n",
      "fp_953: 0.0000\n",
      "fp_954: 0.0000\n",
      "fp_955: 0.0000\n",
      "fp_956: 0.0000\n",
      "fp_957: 0.0000\n",
      "fp_958: 0.0000\n",
      "fp_959: 0.0000\n",
      "fp_960: 0.0000\n",
      "fp_961: 0.0000\n",
      "fp_962: 0.0000\n",
      "fp_963: 0.0000\n",
      "fp_964: 0.0000\n",
      "fp_965: 0.0014\n",
      "fp_966: 0.0000\n",
      "fp_967: 0.0003\n",
      "fp_968: 0.0019\n",
      "fp_969: 0.0000\n",
      "fp_970: 0.0000\n",
      "fp_971: 0.0000\n",
      "fp_972: 0.0000\n",
      "fp_973: 0.0000\n",
      "fp_974: 0.0001\n",
      "fp_975: 0.0000\n",
      "fp_976: 0.0000\n",
      "fp_977: 0.0000\n",
      "fp_978: 0.0000\n",
      "fp_979: 0.0000\n",
      "fp_980: 0.0012\n",
      "fp_981: 0.0010\n",
      "fp_982: 0.0000\n",
      "fp_983: 0.0000\n",
      "fp_984: 0.0000\n",
      "fp_985: 0.0000\n",
      "fp_986: 0.0000\n",
      "fp_987: 0.0000\n",
      "fp_988: 0.0000\n",
      "fp_989: 0.0000\n",
      "fp_990: 0.0000\n",
      "fp_991: 0.0000\n",
      "fp_992: 0.0000\n",
      "fp_993: 0.0020\n",
      "fp_994: 0.0000\n",
      "fp_995: 0.0000\n",
      "fp_996: 0.0000\n",
      "fp_997: 0.0000\n",
      "fp_998: 0.0000\n",
      "fp_999: 0.0000\n",
      "fp_1000: 0.0000\n",
      "fp_1001: 0.0000\n",
      "fp_1002: 0.0000\n",
      "fp_1003: 0.0003\n",
      "fp_1004: 0.0000\n",
      "fp_1005: 0.0000\n",
      "fp_1006: 0.0000\n",
      "fp_1007: 0.0000\n",
      "fp_1008: 0.0000\n",
      "fp_1009: 0.0000\n",
      "fp_1010: 0.0000\n",
      "fp_1011: 0.0000\n",
      "fp_1012: 0.0000\n",
      "fp_1013: 0.0016\n",
      "fp_1014: 0.0011\n",
      "fp_1015: 0.0000\n",
      "fp_1016: 0.0000\n",
      "fp_1017: 0.0026\n",
      "fp_1018: 0.0000\n",
      "fp_1019: 0.0007\n",
      "fp_1020: 0.0000\n",
      "fp_1021: 0.0000\n",
      "fp_1022: 0.0000\n",
      "fp_1023: 0.0000\n",
      "fp_1024: 0.0000\n",
      "fp_1025: 0.0000\n",
      "fp_1026: 0.0000\n",
      "fp_1027: 0.0044\n",
      "fp_1028: 0.0000\n",
      "fp_1029: 0.0000\n",
      "fp_1030: 0.0009\n",
      "fp_1031: 0.0000\n",
      "fp_1032: 0.0021\n",
      "fp_1033: 0.0000\n",
      "fp_1034: 0.0000\n",
      "fp_1035: 0.0000\n",
      "fp_1036: 0.0000\n",
      "fp_1037: 0.0000\n",
      "fp_1038: 0.0000\n",
      "fp_1039: 0.0009\n",
      "fp_1040: 0.0000\n",
      "fp_1041: 0.0000\n",
      "fp_1042: 0.0000\n",
      "fp_1043: 0.0011\n",
      "fp_1044: 0.0000\n",
      "fp_1045: 0.0000\n",
      "fp_1046: 0.0000\n",
      "fp_1047: 0.0000\n",
      "fp_1048: 0.0000\n",
      "fp_1049: 0.0011\n",
      "fp_1050: 0.0000\n",
      "fp_1051: 0.0000\n",
      "fp_1052: 0.0000\n",
      "fp_1053: 0.0000\n",
      "fp_1054: 0.0000\n",
      "fp_1055: 0.0019\n",
      "fp_1056: 0.0015\n",
      "fp_1057: 0.0006\n",
      "fp_1058: 0.0000\n",
      "fp_1059: 0.0000\n",
      "fp_1060: 0.0000\n",
      "fp_1061: 0.0000\n",
      "fp_1062: 0.0000\n",
      "fp_1063: 0.0011\n",
      "fp_1064: 0.0000\n",
      "fp_1065: 0.0000\n",
      "fp_1066: 0.0000\n",
      "fp_1067: 0.0000\n",
      "fp_1068: 0.0015\n",
      "fp_1069: 0.0000\n",
      "fp_1070: 0.0058\n",
      "fp_1071: 0.0072\n",
      "fp_1072: 0.0000\n",
      "fp_1073: 0.0000\n",
      "fp_1074: 0.0000\n",
      "fp_1075: 0.0000\n",
      "fp_1076: 0.0010\n",
      "fp_1077: 0.0000\n",
      "fp_1078: 0.0000\n",
      "fp_1079: 0.0000\n",
      "fp_1080: 0.0000\n",
      "fp_1081: 0.0007\n",
      "fp_1082: 0.0000\n",
      "fp_1083: 0.0007\n",
      "fp_1084: 0.0000\n",
      "fp_1085: 0.0000\n",
      "fp_1086: 0.0018\n",
      "fp_1087: 0.0010\n",
      "fp_1088: 0.0004\n",
      "fp_1089: 0.0000\n",
      "fp_1090: 0.0000\n",
      "fp_1091: 0.0000\n",
      "fp_1092: 0.0000\n",
      "fp_1093: 0.0000\n",
      "fp_1094: 0.0000\n",
      "fp_1095: 0.0000\n",
      "fp_1096: 0.0000\n",
      "fp_1097: 0.0009\n",
      "fp_1098: 0.0009\n",
      "fp_1099: 0.0013\n",
      "fp_1100: 0.0000\n",
      "fp_1101: 0.0037\n",
      "fp_1102: 0.0000\n",
      "fp_1103: 0.0011\n",
      "fp_1104: 0.0000\n",
      "fp_1105: 0.0033\n",
      "fp_1106: 0.0000\n",
      "fp_1107: 0.0000\n",
      "fp_1108: 0.0014\n",
      "fp_1109: 0.0000\n",
      "fp_1110: 0.0000\n",
      "fp_1111: 0.0000\n",
      "fp_1112: 0.0000\n",
      "fp_1113: 0.0223\n",
      "fp_1114: 0.0017\n",
      "fp_1115: 0.0000\n",
      "fp_1116: 0.0000\n",
      "fp_1117: 0.0000\n",
      "fp_1118: 0.0000\n",
      "fp_1119: 0.0000\n",
      "fp_1120: 0.0000\n",
      "fp_1121: 0.0000\n",
      "fp_1122: 0.0010\n",
      "fp_1123: 0.0000\n",
      "fp_1124: 0.0000\n",
      "fp_1125: 0.0000\n",
      "fp_1126: 0.0000\n",
      "fp_1127: 0.0000\n",
      "fp_1128: 0.0000\n",
      "fp_1129: 0.0135\n",
      "fp_1130: 0.0000\n",
      "fp_1131: 0.0000\n",
      "fp_1132: 0.0000\n",
      "fp_1133: 0.0000\n",
      "fp_1134: 0.0012\n",
      "fp_1135: 0.0000\n",
      "fp_1136: 0.0000\n",
      "fp_1137: 0.0000\n",
      "fp_1138: 0.0000\n",
      "fp_1139: 0.0000\n",
      "fp_1140: 0.0000\n",
      "fp_1141: 0.0006\n",
      "fp_1142: 0.0000\n",
      "fp_1143: 0.0000\n",
      "fp_1144: 0.0000\n",
      "fp_1145: 0.0016\n",
      "fp_1146: 0.0000\n",
      "fp_1147: 0.0011\n",
      "fp_1148: 0.0000\n",
      "fp_1149: 0.0000\n",
      "fp_1150: 0.0000\n",
      "fp_1151: 0.0000\n",
      "fp_1152: 0.0009\n",
      "fp_1153: 0.0000\n",
      "fp_1154: 0.0005\n",
      "fp_1155: 0.0000\n",
      "fp_1156: 0.0000\n",
      "fp_1157: 0.0018\n",
      "fp_1158: 0.0000\n",
      "fp_1159: 0.0000\n",
      "fp_1160: 0.0000\n",
      "fp_1161: 0.0055\n",
      "fp_1162: 0.0000\n",
      "fp_1163: 0.0000\n",
      "fp_1164: 0.0027\n",
      "fp_1165: 0.0000\n",
      "fp_1166: 0.0000\n",
      "fp_1167: 0.0000\n",
      "fp_1168: 0.0000\n",
      "fp_1169: 0.0000\n",
      "fp_1170: 0.0004\n",
      "fp_1171: 0.0000\n",
      "fp_1172: 0.0012\n",
      "fp_1173: 0.0000\n",
      "fp_1174: 0.0000\n",
      "fp_1175: 0.0000\n",
      "fp_1176: 0.0000\n",
      "fp_1177: 0.0000\n",
      "fp_1178: 0.0000\n",
      "fp_1179: 0.0000\n",
      "fp_1180: 0.0000\n",
      "fp_1181: 0.0000\n",
      "fp_1182: 0.0000\n",
      "fp_1183: 0.0000\n",
      "fp_1184: 0.0000\n",
      "fp_1185: 0.0015\n",
      "fp_1186: 0.0000\n",
      "fp_1187: 0.0000\n",
      "fp_1188: 0.0000\n",
      "fp_1189: 0.0000\n",
      "fp_1190: 0.0000\n",
      "fp_1191: 0.0000\n",
      "fp_1192: 0.0000\n",
      "fp_1193: 0.0000\n",
      "fp_1194: 0.0010\n",
      "fp_1195: 0.0000\n",
      "fp_1196: 0.0000\n",
      "fp_1197: 0.0000\n",
      "fp_1198: 0.0000\n",
      "fp_1199: 0.0019\n",
      "fp_1200: 0.0000\n",
      "fp_1201: 0.0000\n",
      "fp_1202: 0.0000\n",
      "fp_1203: 0.0000\n",
      "fp_1204: 0.0000\n",
      "fp_1205: 0.0000\n",
      "fp_1206: 0.0000\n",
      "fp_1207: 0.0000\n",
      "fp_1208: 0.0013\n",
      "fp_1209: 0.0000\n",
      "fp_1210: 0.0000\n",
      "fp_1211: 0.0000\n",
      "fp_1212: 0.0000\n",
      "fp_1213: 0.0000\n",
      "fp_1214: 0.0000\n",
      "fp_1215: 0.0000\n",
      "fp_1216: 0.0000\n",
      "fp_1217: 0.0015\n",
      "fp_1218: 0.0033\n",
      "fp_1219: 0.0000\n",
      "fp_1220: 0.0000\n",
      "fp_1221: 0.0000\n",
      "fp_1222: 0.0000\n",
      "fp_1223: 0.0000\n",
      "fp_1224: 0.0000\n",
      "fp_1225: 0.0000\n",
      "fp_1226: 0.0000\n",
      "fp_1227: 0.0000\n",
      "fp_1228: 0.0000\n",
      "fp_1229: 0.0000\n",
      "fp_1230: 0.0000\n",
      "fp_1231: 0.0000\n",
      "fp_1232: 0.0003\n",
      "fp_1233: 0.0000\n",
      "fp_1234: 0.0000\n",
      "fp_1235: 0.0000\n",
      "fp_1236: 0.0002\n",
      "fp_1237: 0.0000\n",
      "fp_1238: 0.0012\n",
      "fp_1239: 0.0029\n",
      "fp_1240: 0.0000\n",
      "fp_1241: 0.0023\n",
      "fp_1242: 0.0000\n",
      "fp_1243: 0.0000\n",
      "fp_1244: 0.0000\n",
      "fp_1245: 0.0000\n",
      "fp_1246: 0.0000\n",
      "fp_1247: 0.0000\n",
      "fp_1248: 0.0000\n",
      "fp_1249: 0.0000\n",
      "fp_1250: 0.0000\n",
      "fp_1251: 0.0000\n",
      "fp_1252: 0.0000\n",
      "fp_1253: 0.0000\n",
      "fp_1254: 0.0034\n",
      "fp_1255: 0.0000\n",
      "fp_1256: 0.0000\n",
      "fp_1257: 0.0010\n",
      "fp_1258: 0.0000\n",
      "fp_1259: 0.0000\n",
      "fp_1260: 0.0000\n",
      "fp_1261: 0.0000\n",
      "fp_1262: 0.0000\n",
      "fp_1263: 0.0000\n",
      "fp_1264: 0.0000\n",
      "fp_1265: 0.0000\n",
      "fp_1266: 0.0000\n",
      "fp_1267: 0.0000\n",
      "fp_1268: 0.0000\n",
      "fp_1269: 0.0000\n",
      "fp_1270: 0.0000\n",
      "fp_1271: 0.0000\n",
      "fp_1272: 0.0000\n",
      "fp_1273: 0.0022\n",
      "fp_1274: 0.0000\n",
      "fp_1275: 0.0027\n",
      "fp_1276: 0.0021\n",
      "fp_1277: 0.0000\n",
      "fp_1278: 0.0000\n",
      "fp_1279: 0.0000\n",
      "fp_1280: 0.0000\n",
      "fp_1281: 0.0000\n",
      "fp_1282: 0.0000\n",
      "fp_1283: 0.0000\n",
      "fp_1284: 0.0000\n",
      "fp_1285: 0.0000\n",
      "fp_1286: 0.0000\n",
      "fp_1287: 0.0020\n",
      "fp_1288: 0.0000\n",
      "fp_1289: 0.0000\n",
      "fp_1290: 0.0000\n",
      "fp_1291: 0.0000\n",
      "fp_1292: 0.0000\n",
      "fp_1293: 0.0000\n",
      "fp_1294: 0.0000\n",
      "fp_1295: 0.0047\n",
      "fp_1296: 0.0000\n",
      "fp_1297: 0.0000\n",
      "fp_1298: 0.0000\n",
      "fp_1299: 0.0000\n",
      "fp_1300: 0.0000\n",
      "fp_1301: 0.0000\n",
      "fp_1302: 0.0000\n",
      "fp_1303: 0.0000\n",
      "fp_1304: 0.0000\n",
      "fp_1305: 0.0000\n",
      "fp_1306: 0.0000\n",
      "fp_1307: 0.0000\n",
      "fp_1308: 0.0000\n",
      "fp_1309: 0.0036\n",
      "fp_1310: 0.0000\n",
      "fp_1311: 0.0000\n",
      "fp_1312: 0.0029\n",
      "fp_1313: 0.0000\n",
      "fp_1314: 0.0000\n",
      "fp_1315: 0.0000\n",
      "fp_1316: 0.0000\n",
      "fp_1317: 0.0000\n",
      "fp_1318: 0.0000\n",
      "fp_1319: 0.0000\n",
      "fp_1320: 0.0000\n",
      "fp_1321: 0.0000\n",
      "fp_1322: 0.0000\n",
      "fp_1323: 0.0000\n",
      "fp_1324: 0.0000\n",
      "fp_1325: 0.0001\n",
      "fp_1326: 0.0000\n",
      "fp_1327: 0.0000\n",
      "fp_1328: 0.0000\n",
      "fp_1329: 0.0000\n",
      "fp_1330: 0.0000\n",
      "fp_1331: 0.0000\n",
      "fp_1332: 0.0011\n",
      "fp_1333: 0.0000\n",
      "fp_1334: 0.0000\n",
      "fp_1335: 0.0000\n",
      "fp_1336: 0.0000\n",
      "fp_1337: 0.0000\n",
      "fp_1338: 0.0000\n",
      "fp_1339: 0.0000\n",
      "fp_1340: 0.0000\n",
      "fp_1341: 0.0000\n",
      "fp_1342: 0.0000\n",
      "fp_1343: 0.0000\n",
      "fp_1344: 0.0000\n",
      "fp_1345: 0.0000\n",
      "fp_1346: 0.0000\n",
      "fp_1347: 0.0000\n",
      "fp_1348: 0.0000\n",
      "fp_1349: 0.0000\n",
      "fp_1350: 0.0000\n",
      "fp_1351: 0.0000\n",
      "fp_1352: 0.0000\n",
      "fp_1353: 0.0000\n",
      "fp_1354: 0.0000\n",
      "fp_1355: 0.0019\n",
      "fp_1356: 0.0007\n",
      "fp_1357: 0.0062\n",
      "fp_1358: 0.0000\n",
      "fp_1359: 0.0000\n",
      "fp_1360: 0.0000\n",
      "fp_1361: 0.0000\n",
      "fp_1362: 0.0012\n",
      "fp_1363: 0.0020\n",
      "fp_1364: 0.0000\n",
      "fp_1365: 0.0000\n",
      "fp_1366: 0.0000\n",
      "fp_1367: 0.0000\n",
      "fp_1368: 0.0013\n",
      "fp_1369: 0.0000\n",
      "fp_1370: 0.0000\n",
      "fp_1371: 0.0000\n",
      "fp_1372: 0.0000\n",
      "fp_1373: 0.0000\n",
      "fp_1374: 0.0000\n",
      "fp_1375: 0.0000\n",
      "fp_1376: 0.0000\n",
      "fp_1377: 0.0000\n",
      "fp_1378: 0.0000\n",
      "fp_1379: 0.0000\n",
      "fp_1380: 0.0000\n",
      "fp_1381: 0.0000\n",
      "fp_1382: 0.0000\n",
      "fp_1383: 0.0000\n",
      "fp_1384: 0.0019\n",
      "fp_1385: 0.0023\n",
      "fp_1386: 0.0000\n",
      "fp_1387: 0.0000\n",
      "fp_1388: 0.0000\n",
      "fp_1389: 0.0000\n",
      "fp_1390: 0.0000\n",
      "fp_1391: 0.0010\n",
      "fp_1392: 0.0000\n",
      "fp_1393: 0.0000\n",
      "fp_1394: 0.0000\n",
      "fp_1395: 0.0000\n",
      "fp_1396: 0.0000\n",
      "fp_1397: 0.0000\n",
      "fp_1398: 0.0000\n",
      "fp_1399: 0.0000\n",
      "fp_1400: 0.0012\n",
      "fp_1401: 0.0000\n",
      "fp_1402: 0.0010\n",
      "fp_1403: 0.0010\n",
      "fp_1404: 0.0000\n",
      "fp_1405: 0.0000\n",
      "fp_1406: 0.0000\n",
      "fp_1407: 0.0000\n",
      "fp_1408: 0.0000\n",
      "fp_1409: 0.0000\n",
      "fp_1410: 0.0009\n",
      "fp_1411: 0.0000\n",
      "fp_1412: 0.0022\n",
      "fp_1413: 0.0000\n",
      "fp_1414: 0.0000\n",
      "fp_1415: 0.0000\n",
      "fp_1416: 0.0000\n",
      "fp_1417: 0.0003\n",
      "fp_1418: 0.0000\n",
      "fp_1419: 0.0000\n",
      "fp_1420: 0.0000\n",
      "fp_1421: 0.0000\n",
      "fp_1422: 0.0000\n",
      "fp_1423: 0.0000\n",
      "fp_1424: 0.0000\n",
      "fp_1425: 0.0000\n",
      "fp_1426: 0.0000\n",
      "fp_1427: 0.0000\n",
      "fp_1428: 0.0000\n",
      "fp_1429: 0.0000\n",
      "fp_1430: 0.0011\n",
      "fp_1431: 0.0000\n",
      "fp_1432: 0.0000\n",
      "fp_1433: 0.0000\n",
      "fp_1434: 0.0023\n",
      "fp_1435: 0.0000\n",
      "fp_1436: 0.0000\n",
      "fp_1437: 0.0000\n",
      "fp_1438: 0.0018\n",
      "fp_1439: 0.0000\n",
      "fp_1440: 0.0000\n",
      "fp_1441: 0.0000\n",
      "fp_1442: 0.0022\n",
      "fp_1443: 0.0025\n",
      "fp_1444: 0.0000\n",
      "fp_1445: 0.0000\n",
      "fp_1446: 0.0000\n",
      "fp_1447: 0.0011\n",
      "fp_1448: 0.0000\n",
      "fp_1449: 0.0000\n",
      "fp_1450: 0.0000\n",
      "fp_1451: 0.0000\n",
      "fp_1452: 0.0011\n",
      "fp_1453: 0.0009\n",
      "fp_1454: 0.0000\n",
      "fp_1455: 0.0001\n",
      "fp_1456: 0.0000\n",
      "fp_1457: 0.0004\n",
      "fp_1458: 0.0000\n",
      "fp_1459: 0.0000\n",
      "fp_1460: 0.0000\n",
      "fp_1461: 0.0000\n",
      "fp_1462: 0.0000\n",
      "fp_1463: 0.0000\n",
      "fp_1464: 0.0000\n",
      "fp_1465: 0.0000\n",
      "fp_1466: 0.0000\n",
      "fp_1467: 0.0000\n",
      "fp_1468: 0.0009\n",
      "fp_1469: 0.0000\n",
      "fp_1470: 0.0017\n",
      "fp_1471: 0.0000\n",
      "fp_1472: 0.0000\n",
      "fp_1473: 0.0000\n",
      "fp_1474: 0.0000\n",
      "fp_1475: 0.0000\n",
      "fp_1476: 0.0034\n",
      "fp_1477: 0.0000\n",
      "fp_1478: 0.0000\n",
      "fp_1479: 0.0000\n",
      "fp_1480: 0.0012\n",
      "fp_1481: 0.0000\n",
      "fp_1482: 0.0000\n",
      "fp_1483: 0.0000\n",
      "fp_1484: 0.0000\n",
      "fp_1485: 0.0000\n",
      "fp_1486: 0.0000\n",
      "fp_1487: 0.0006\n",
      "fp_1488: 0.0000\n",
      "fp_1489: 0.0000\n",
      "fp_1490: 0.0000\n",
      "fp_1491: 0.0000\n",
      "fp_1492: 0.0000\n",
      "fp_1493: 0.0000\n",
      "fp_1494: 0.0000\n",
      "fp_1495: 0.0000\n",
      "fp_1496: 0.0000\n",
      "fp_1497: 0.0000\n",
      "fp_1498: 0.0000\n",
      "fp_1499: 0.0000\n",
      "fp_1500: 0.0000\n",
      "fp_1501: 0.0013\n",
      "fp_1502: 0.0000\n",
      "fp_1503: 0.0000\n",
      "fp_1504: 0.0000\n",
      "fp_1505: 0.0000\n",
      "fp_1506: 0.0000\n",
      "fp_1507: 0.0000\n",
      "fp_1508: 0.0000\n",
      "fp_1509: 0.0000\n",
      "fp_1510: 0.0000\n",
      "fp_1511: 0.0000\n",
      "fp_1512: 0.0000\n",
      "fp_1513: 0.0000\n",
      "fp_1514: 0.0000\n",
      "fp_1515: 0.0000\n",
      "fp_1516: 0.0000\n",
      "fp_1517: 0.0000\n",
      "fp_1518: 0.0000\n",
      "fp_1519: 0.0000\n",
      "fp_1520: 0.0000\n",
      "fp_1521: 0.0000\n",
      "fp_1522: 0.0000\n",
      "fp_1523: 0.0000\n",
      "fp_1524: 0.0000\n",
      "fp_1525: 0.0000\n",
      "fp_1526: 0.0000\n",
      "fp_1527: 0.0000\n",
      "fp_1528: 0.0000\n",
      "fp_1529: 0.0079\n",
      "fp_1530: 0.0030\n",
      "fp_1531: 0.0000\n",
      "fp_1532: 0.0000\n",
      "fp_1533: 0.0000\n",
      "fp_1534: 0.0000\n",
      "fp_1535: 0.0000\n",
      "fp_1536: 0.0277\n",
      "fp_1537: 0.0000\n",
      "fp_1538: 0.0000\n",
      "fp_1539: 0.0000\n",
      "fp_1540: 0.0000\n",
      "fp_1541: 0.0000\n",
      "fp_1542: 0.0012\n",
      "fp_1543: 0.0000\n",
      "fp_1544: 0.0005\n",
      "fp_1545: 0.0000\n",
      "fp_1546: 0.0013\n",
      "fp_1547: 0.0000\n",
      "fp_1548: 0.0000\n",
      "fp_1549: 0.0000\n",
      "fp_1550: 0.0000\n",
      "fp_1551: 0.0000\n",
      "fp_1552: 0.0000\n",
      "fp_1553: 0.0000\n",
      "fp_1554: 0.0000\n",
      "fp_1555: 0.0000\n",
      "fp_1556: 0.0000\n",
      "fp_1557: 0.0000\n",
      "fp_1558: 0.0000\n",
      "fp_1559: 0.0000\n",
      "fp_1560: 0.0000\n",
      "fp_1561: 0.0000\n",
      "fp_1562: 0.0009\n",
      "fp_1563: 0.0047\n",
      "fp_1564: 0.0000\n",
      "fp_1565: 0.0000\n",
      "fp_1566: 0.0000\n",
      "fp_1567: 0.0000\n",
      "fp_1568: 0.0000\n",
      "fp_1569: 0.0015\n",
      "fp_1570: 0.0000\n",
      "fp_1571: 0.0000\n",
      "fp_1572: 0.0000\n",
      "fp_1573: 0.0009\n",
      "fp_1574: 0.0000\n",
      "fp_1575: 0.0000\n",
      "fp_1576: 0.0000\n",
      "fp_1577: 0.0012\n",
      "fp_1578: 0.0000\n",
      "fp_1579: 0.0000\n",
      "fp_1580: 0.0000\n",
      "fp_1581: 0.0000\n",
      "fp_1582: 0.0000\n",
      "fp_1583: 0.0000\n",
      "fp_1584: 0.0000\n",
      "fp_1585: 0.0000\n",
      "fp_1586: 0.0007\n",
      "fp_1587: 0.0012\n",
      "fp_1588: 0.0000\n",
      "fp_1589: 0.0000\n",
      "fp_1590: 0.0014\n",
      "fp_1591: 0.0000\n",
      "fp_1592: 0.0000\n",
      "fp_1593: 0.0000\n",
      "fp_1594: 0.0000\n",
      "fp_1595: 0.0000\n",
      "fp_1596: 0.0010\n",
      "fp_1597: 0.0000\n",
      "fp_1598: 0.0000\n",
      "fp_1599: 0.0000\n",
      "fp_1600: 0.0000\n",
      "fp_1601: 0.0046\n",
      "fp_1602: 0.0016\n",
      "fp_1603: 0.0019\n",
      "fp_1604: 0.0020\n",
      "fp_1605: 0.0000\n",
      "fp_1606: 0.0000\n",
      "fp_1607: 0.0012\n",
      "fp_1608: 0.0000\n",
      "fp_1609: 0.0000\n",
      "fp_1610: 0.0000\n",
      "fp_1611: 0.0000\n",
      "fp_1612: 0.0014\n",
      "fp_1613: 0.0000\n",
      "fp_1614: 0.0000\n",
      "fp_1615: 0.0000\n",
      "fp_1616: 0.0000\n",
      "fp_1617: 0.0000\n",
      "fp_1618: 0.0000\n",
      "fp_1619: 0.0000\n",
      "fp_1620: 0.0000\n",
      "fp_1621: 0.0028\n",
      "fp_1622: 0.0000\n",
      "fp_1623: 0.0008\n",
      "fp_1624: 0.0000\n",
      "fp_1625: 0.0000\n",
      "fp_1626: 0.0059\n",
      "fp_1627: 0.0000\n",
      "fp_1628: 0.0000\n",
      "fp_1629: 0.0000\n",
      "fp_1630: 0.0016\n",
      "fp_1631: 0.0000\n",
      "fp_1632: 0.0000\n",
      "fp_1633: 0.0000\n",
      "fp_1634: 0.0016\n",
      "fp_1635: 0.0000\n",
      "fp_1636: 0.0000\n",
      "fp_1637: 0.0000\n",
      "fp_1638: 0.0000\n",
      "fp_1639: 0.0013\n",
      "fp_1640: 0.0000\n",
      "fp_1641: 0.0000\n",
      "fp_1642: 0.0000\n",
      "fp_1643: 0.0000\n",
      "fp_1644: 0.0018\n",
      "fp_1645: 0.0000\n",
      "fp_1646: 0.0018\n",
      "fp_1647: 0.0000\n",
      "fp_1648: 0.0000\n",
      "fp_1649: 0.0000\n",
      "fp_1650: 0.0000\n",
      "fp_1651: 0.0000\n",
      "fp_1652: 0.0000\n",
      "fp_1653: 0.0000\n",
      "fp_1654: 0.0000\n",
      "fp_1655: 0.0013\n",
      "fp_1656: 0.0000\n",
      "fp_1657: 0.0013\n",
      "fp_1658: 0.0000\n",
      "fp_1659: 0.0000\n",
      "fp_1660: 0.0018\n",
      "fp_1661: 0.0000\n",
      "fp_1662: 0.0000\n",
      "fp_1663: 0.0007\n",
      "fp_1664: 0.0000\n",
      "fp_1665: 0.0054\n",
      "fp_1666: 0.0000\n",
      "fp_1667: 0.0014\n",
      "fp_1668: 0.0000\n",
      "fp_1669: 0.0000\n",
      "fp_1670: 0.0000\n",
      "fp_1671: 0.0011\n",
      "fp_1672: 0.0000\n",
      "fp_1673: 0.0000\n",
      "fp_1674: 0.0000\n",
      "fp_1675: 0.0010\n",
      "fp_1676: 0.0000\n",
      "fp_1677: 0.0013\n",
      "fp_1678: 0.0000\n",
      "fp_1679: 0.0017\n",
      "fp_1680: 0.0000\n",
      "fp_1681: 0.0000\n",
      "fp_1682: 0.0071\n",
      "fp_1683: 0.0000\n",
      "fp_1684: 0.0000\n",
      "fp_1685: 0.0014\n",
      "fp_1686: 0.0000\n",
      "fp_1687: 0.0000\n",
      "fp_1688: 0.0000\n",
      "fp_1689: 0.0000\n",
      "fp_1690: 0.0000\n",
      "fp_1691: 0.0000\n",
      "fp_1692: 0.0000\n",
      "fp_1693: 0.0000\n",
      "fp_1694: 0.0000\n",
      "fp_1695: 0.0000\n",
      "fp_1696: 0.0000\n",
      "fp_1697: 0.0004\n",
      "fp_1698: 0.0000\n",
      "fp_1699: 0.0009\n",
      "fp_1700: 0.0000\n",
      "fp_1701: 0.0000\n",
      "fp_1702: 0.0012\n",
      "fp_1703: 0.0000\n",
      "fp_1704: 0.0000\n",
      "fp_1705: 0.0000\n",
      "fp_1706: 0.0012\n",
      "fp_1707: 0.0000\n",
      "fp_1708: 0.0000\n",
      "fp_1709: 0.0000\n",
      "fp_1710: 0.0000\n",
      "fp_1711: 0.0000\n",
      "fp_1712: 0.0000\n",
      "fp_1713: 0.0000\n",
      "fp_1714: 0.0000\n",
      "fp_1715: 0.0000\n",
      "fp_1716: 0.0000\n",
      "fp_1717: 0.0046\n",
      "fp_1718: 0.0000\n",
      "fp_1719: 0.0000\n",
      "fp_1720: 0.0000\n",
      "fp_1721: 0.0000\n",
      "fp_1722: 0.0038\n",
      "fp_1723: 0.0000\n",
      "fp_1724: 0.0000\n",
      "fp_1725: 0.0000\n",
      "fp_1726: 0.0000\n",
      "fp_1727: 0.0000\n",
      "fp_1728: 0.0000\n",
      "fp_1729: 0.0000\n",
      "fp_1730: 0.0000\n",
      "fp_1731: 0.0000\n",
      "fp_1732: 0.0000\n",
      "fp_1733: 0.0000\n",
      "fp_1734: 0.0000\n",
      "fp_1735: 0.0000\n",
      "fp_1736: 0.0000\n",
      "fp_1737: 0.0017\n",
      "fp_1738: 0.0025\n",
      "fp_1739: 0.0000\n",
      "fp_1740: 0.0000\n",
      "fp_1741: 0.0000\n",
      "fp_1742: 0.0000\n",
      "fp_1743: 0.0000\n",
      "fp_1744: 0.0000\n",
      "fp_1745: 0.0006\n",
      "fp_1746: 0.0000\n",
      "fp_1747: 0.0018\n",
      "fp_1748: 0.0000\n",
      "fp_1749: 0.0000\n",
      "fp_1750: 0.0020\n",
      "fp_1751: 0.0000\n",
      "fp_1752: 0.0000\n",
      "fp_1753: 0.0000\n",
      "fp_1754: 0.0005\n",
      "fp_1755: 0.0000\n",
      "fp_1756: 0.0000\n",
      "fp_1757: 0.0000\n",
      "fp_1758: 0.0006\n",
      "fp_1759: 0.0000\n",
      "fp_1760: 0.0010\n",
      "fp_1761: 0.0000\n",
      "fp_1762: 0.0013\n",
      "fp_1763: 0.0000\n",
      "fp_1764: 0.0000\n",
      "fp_1765: 0.0000\n",
      "fp_1766: 0.0013\n",
      "fp_1767: 0.0000\n",
      "fp_1768: 0.0000\n",
      "fp_1769: 0.0000\n",
      "fp_1770: 0.0000\n",
      "fp_1771: 0.0000\n",
      "fp_1772: 0.0000\n",
      "fp_1773: 0.0000\n",
      "fp_1774: 0.0000\n",
      "fp_1775: 0.0013\n",
      "fp_1776: 0.0000\n",
      "fp_1777: 0.0012\n",
      "fp_1778: 0.0000\n",
      "fp_1779: 0.0000\n",
      "fp_1780: 0.0000\n",
      "fp_1781: 0.0000\n",
      "fp_1782: 0.0000\n",
      "fp_1783: 0.0003\n",
      "fp_1784: 0.0000\n",
      "fp_1785: 0.0000\n",
      "fp_1786: 0.0000\n",
      "fp_1787: 0.0000\n",
      "fp_1788: 0.0000\n",
      "fp_1789: 0.0000\n",
      "fp_1790: 0.0000\n",
      "fp_1791: 0.0000\n",
      "fp_1792: 0.0000\n",
      "fp_1793: 0.0000\n",
      "fp_1794: 0.0000\n",
      "fp_1795: 0.0011\n",
      "fp_1796: 0.0000\n",
      "fp_1797: 0.0000\n",
      "fp_1798: 0.0000\n",
      "fp_1799: 0.0000\n",
      "fp_1800: 0.0000\n",
      "fp_1801: 0.0000\n",
      "fp_1802: 0.0000\n",
      "fp_1803: 0.0000\n",
      "fp_1804: 0.0000\n",
      "fp_1805: 0.0000\n",
      "fp_1806: 0.0012\n",
      "fp_1807: 0.0000\n",
      "fp_1808: 0.0000\n",
      "fp_1809: 0.0000\n",
      "fp_1810: 0.0000\n",
      "fp_1811: 0.0000\n",
      "fp_1812: 0.0000\n",
      "fp_1813: 0.0000\n",
      "fp_1814: 0.0008\n",
      "fp_1815: 0.0000\n",
      "fp_1816: 0.0000\n",
      "fp_1817: 0.0000\n",
      "fp_1818: 0.0011\n",
      "fp_1819: 0.0000\n",
      "fp_1820: 0.0000\n",
      "fp_1821: 0.0000\n",
      "fp_1822: 0.0000\n",
      "fp_1823: 0.0000\n",
      "fp_1824: 0.0000\n",
      "fp_1825: 0.0000\n",
      "fp_1826: 0.0000\n",
      "fp_1827: 0.0000\n",
      "fp_1828: 0.0000\n",
      "fp_1829: 0.0000\n",
      "fp_1830: 0.0000\n",
      "fp_1831: 0.0000\n",
      "fp_1832: 0.0000\n",
      "fp_1833: 0.0008\n",
      "fp_1834: 0.0000\n",
      "fp_1835: 0.0000\n",
      "fp_1836: 0.0000\n",
      "fp_1837: 0.0000\n",
      "fp_1838: 0.0000\n",
      "fp_1839: 0.0000\n",
      "fp_1840: 0.0034\n",
      "fp_1841: 0.0000\n",
      "fp_1842: 0.0038\n",
      "fp_1843: 0.0000\n",
      "fp_1844: 0.0013\n",
      "fp_1845: 0.0000\n",
      "fp_1846: 0.0000\n",
      "fp_1847: 0.0000\n",
      "fp_1848: 0.0000\n",
      "fp_1849: 0.0000\n",
      "fp_1850: 0.0000\n",
      "fp_1851: 0.0305\n",
      "fp_1852: 0.0000\n",
      "fp_1853: 0.0000\n",
      "fp_1854: 0.0000\n",
      "fp_1855: 0.0012\n",
      "fp_1856: 0.0000\n",
      "fp_1857: 0.0000\n",
      "fp_1858: 0.0000\n",
      "fp_1859: 0.0000\n",
      "fp_1860: 0.0000\n",
      "fp_1861: 0.0000\n",
      "fp_1862: 0.0009\n",
      "fp_1863: 0.0000\n",
      "fp_1864: 0.0000\n",
      "fp_1865: 0.0015\n",
      "fp_1866: 0.0003\n",
      "fp_1867: 0.0000\n",
      "fp_1868: 0.0000\n",
      "fp_1869: 0.0000\n",
      "fp_1870: 0.0000\n",
      "fp_1871: 0.0000\n",
      "fp_1872: 0.0000\n",
      "fp_1873: 0.0000\n",
      "fp_1874: 0.0000\n",
      "fp_1875: 0.0000\n",
      "fp_1876: 0.0000\n",
      "fp_1877: 0.0000\n",
      "fp_1878: 0.0000\n",
      "fp_1879: 0.0036\n",
      "fp_1880: 0.0017\n",
      "fp_1881: 0.0000\n",
      "fp_1882: 0.0000\n",
      "fp_1883: 0.0000\n",
      "fp_1884: 0.0000\n",
      "fp_1885: 0.0000\n",
      "fp_1886: 0.0000\n",
      "fp_1887: 0.0000\n",
      "fp_1888: 0.0000\n",
      "fp_1889: 0.0000\n",
      "fp_1890: 0.0000\n",
      "fp_1891: 0.0000\n",
      "fp_1892: 0.0000\n",
      "fp_1893: 0.0000\n",
      "fp_1894: 0.0000\n",
      "fp_1895: 0.0546\n",
      "fp_1896: 0.0011\n",
      "fp_1897: 0.0014\n",
      "fp_1898: 0.0000\n",
      "fp_1899: 0.0000\n",
      "fp_1900: 0.0009\n",
      "fp_1901: 0.0000\n",
      "fp_1902: 0.0000\n",
      "fp_1903: 0.0000\n",
      "fp_1904: 0.0000\n",
      "fp_1905: 0.0000\n",
      "fp_1906: 0.0000\n",
      "fp_1907: 0.0000\n",
      "fp_1908: 0.0015\n",
      "fp_1909: 0.0000\n",
      "fp_1910: 0.0008\n",
      "fp_1911: 0.0000\n",
      "fp_1912: 0.0000\n",
      "fp_1913: 0.0000\n",
      "fp_1914: 0.0000\n",
      "fp_1915: 0.0000\n",
      "fp_1916: 0.0000\n",
      "fp_1917: 0.0017\n",
      "fp_1918: 0.0000\n",
      "fp_1919: 0.0000\n",
      "fp_1920: 0.0000\n",
      "fp_1921: 0.0000\n",
      "fp_1922: 0.0000\n",
      "fp_1923: 0.0000\n",
      "fp_1924: 0.0000\n",
      "fp_1925: 0.0014\n",
      "fp_1926: 0.0000\n",
      "fp_1927: 0.0000\n",
      "fp_1928: 0.0005\n",
      "fp_1929: 0.0000\n",
      "fp_1930: 0.0000\n",
      "fp_1931: 0.0000\n",
      "fp_1932: 0.0000\n",
      "fp_1933: 0.0000\n",
      "fp_1934: 0.0000\n",
      "fp_1935: 0.0000\n",
      "fp_1936: 0.0000\n",
      "fp_1937: 0.0000\n",
      "fp_1938: 0.0000\n",
      "fp_1939: 0.0012\n",
      "fp_1940: 0.0000\n",
      "fp_1941: 0.0000\n",
      "fp_1942: 0.0009\n",
      "fp_1943: 0.0000\n",
      "fp_1944: 0.0000\n",
      "fp_1945: 0.0000\n",
      "fp_1946: 0.0000\n",
      "fp_1947: 0.0000\n",
      "fp_1948: 0.0000\n",
      "fp_1949: 0.0000\n",
      "fp_1950: 0.0000\n",
      "fp_1951: 0.0036\n",
      "fp_1952: 0.0000\n",
      "fp_1953: 0.0000\n",
      "fp_1954: 0.0000\n",
      "fp_1955: 0.0000\n",
      "fp_1956: 0.0006\n",
      "fp_1957: 0.0000\n",
      "fp_1958: 0.0000\n",
      "fp_1959: 0.0000\n",
      "fp_1960: 0.0000\n",
      "fp_1961: 0.0000\n",
      "fp_1962: 0.0000\n",
      "fp_1963: 0.0000\n",
      "fp_1964: 0.0000\n",
      "fp_1965: 0.0000\n",
      "fp_1966: 0.0000\n",
      "fp_1967: 0.0000\n",
      "fp_1968: 0.0012\n",
      "fp_1969: 0.0010\n",
      "fp_1970: 0.0000\n",
      "fp_1971: 0.0000\n",
      "fp_1972: 0.0000\n",
      "fp_1973: 0.0000\n",
      "fp_1974: 0.0000\n",
      "fp_1975: 0.0000\n",
      "fp_1976: 0.0000\n",
      "fp_1977: 0.0000\n",
      "fp_1978: 0.0000\n",
      "fp_1979: 0.0012\n",
      "fp_1980: 0.0000\n",
      "fp_1981: 0.0000\n",
      "fp_1982: 0.0009\n",
      "fp_1983: 0.0000\n",
      "fp_1984: 0.0007\n",
      "fp_1985: 0.0000\n",
      "fp_1986: 0.0000\n",
      "fp_1987: 0.0000\n",
      "fp_1988: 0.0000\n",
      "fp_1989: 0.0000\n",
      "fp_1990: 0.0021\n",
      "fp_1991: 0.0017\n",
      "fp_1992: 0.0000\n",
      "fp_1993: 0.0000\n",
      "fp_1994: 0.0000\n",
      "fp_1995: 0.0000\n",
      "fp_1996: 0.0000\n",
      "fp_1997: 0.0000\n",
      "fp_1998: 0.0012\n",
      "fp_1999: 0.0000\n",
      "fp_2000: 0.0000\n",
      "fp_2001: 0.0000\n",
      "fp_2002: 0.0000\n",
      "fp_2003: 0.0000\n",
      "fp_2004: 0.0000\n",
      "fp_2005: 0.0000\n",
      "fp_2006: 0.0000\n",
      "fp_2007: 0.0014\n",
      "fp_2008: 0.0000\n",
      "fp_2009: 0.0000\n",
      "fp_2010: 0.0000\n",
      "fp_2011: 0.0000\n",
      "fp_2012: 0.0000\n",
      "fp_2013: 0.0000\n",
      "fp_2014: 0.0012\n",
      "fp_2015: 0.0000\n",
      "fp_2016: 0.0000\n",
      "fp_2017: 0.0000\n",
      "fp_2018: 0.0000\n",
      "fp_2019: 0.0000\n",
      "fp_2020: 0.0000\n",
      "fp_2021: 0.0000\n",
      "fp_2022: 0.0000\n",
      "fp_2023: 0.0014\n",
      "fp_2024: 0.0000\n",
      "fp_2025: 0.0000\n",
      "fp_2026: 0.0000\n",
      "fp_2027: 0.0000\n",
      "fp_2028: 0.0000\n",
      "fp_2029: 0.0000\n",
      "fp_2030: 0.0000\n",
      "fp_2031: 0.0000\n",
      "fp_2032: 0.0000\n",
      "fp_2033: 0.0025\n",
      "fp_2034: 0.0000\n",
      "fp_2035: 0.0000\n",
      "fp_2036: 0.0000\n",
      "fp_2037: 0.0011\n",
      "fp_2038: 0.0000\n",
      "fp_2039: 0.0022\n",
      "fp_2040: 0.0000\n",
      "fp_2041: 0.0000\n",
      "fp_2042: 0.0000\n",
      "fp_2043: 0.0000\n",
      "fp_2044: 0.0000\n",
      "fp_2045: 0.0024\n",
      "fp_2046: 0.0000\n",
      "fp_2047: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# 변수 중요도\n",
    "for i, feature in enumerate(X.columns):\n",
    "    print(f\"{feature}: {model.feature_importances_[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b53890",
   "metadata": {},
   "source": [
    "#### Bayesian Optimization으로 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3061372c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:43:20,307] A new study created in memory with name: no-name-00493d1c-dac4-4d07-9739-31a57be5d79e\n",
      "[I 2025-08-08 08:43:28,689] Trial 0 finished with value: 1.4576636990953784 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.016211505122347626, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 0 with value: 1.4576636990953784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4577 | Params: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.016211505122347626, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:43:30,833] Trial 1 finished with value: 1.479741366622859 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.09359369704185914, 'subsample': 0.5, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 0 with value: 1.4576636990953784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4797 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.09359369704185914, 'subsample': 0.5, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:43:41,613] Trial 2 finished with value: 1.4565592871206376 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.010824734302882916, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 2 with value: 1.4565592871206376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4566 | Params: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.010824734302882916, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:43:43,613] Trial 3 finished with value: 1.5403043512790233 and parameters: {'n_estimators': 50, 'max_depth': 10, 'learning_rate': 0.09239319911366099, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 2 with value: 1.4565592871206376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.5403 | Params: {'n_estimators': 50, 'max_depth': 10, 'learning_rate': 0.09239319911366099, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:43:47,397] Trial 4 finished with value: 1.5042895910906262 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.01908360937418457, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 1}. Best is trial 2 with value: 1.4565592871206376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.5043 | Params: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.01908360937418457, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:43:49,375] Trial 5 finished with value: 1.477563890586819 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.09967074197903024, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 0, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 2 with value: 1.4565592871206376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4776 | Params: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.09967074197903024, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 0, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:43:51,691] Trial 6 finished with value: 1.5050195054634985 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.07128698897842878, 'subsample': 0.5, 'colsample_bytree': 0.5, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 2 with value: 1.4565592871206376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.5050 | Params: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.07128698897842878, 'subsample': 0.5, 'colsample_bytree': 0.5, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:43:54,206] Trial 7 finished with value: 1.492588333138879 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.04308352427954002, 'subsample': 0.8, 'colsample_bytree': 0.5, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}. Best is trial 2 with value: 1.4565592871206376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4926 | Params: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.04308352427954002, 'subsample': 0.8, 'colsample_bytree': 0.5, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:43:56,737] Trial 8 finished with value: 1.4710268463348997 and parameters: {'n_estimators': 50, 'max_depth': 7, 'learning_rate': 0.03856903011277805, 'subsample': 0.8, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 1}. Best is trial 2 with value: 1.4565592871206376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4710 | Params: {'n_estimators': 50, 'max_depth': 7, 'learning_rate': 0.03856903011277805, 'subsample': 0.8, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:43:59,642] Trial 9 finished with value: 1.4713763662883177 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.03862949688492987, 'subsample': 0.8, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 2 with value: 1.4565592871206376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4714 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.03862949688492987, 'subsample': 0.8, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:44:03,032] Trial 10 finished with value: 1.5369254194199702 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.011051708164345813, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.01, 'reg_lambda': 0}. Best is trial 2 with value: 1.4565592871206376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.5369 | Params: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.011051708164345813, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.01, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:44:11,078] Trial 11 finished with value: 1.4718264986357819 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.010312824250394325, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 10}. Best is trial 2 with value: 1.4565592871206376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4718 | Params: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.010312824250394325, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:44:19,595] Trial 12 finished with value: 1.4584211993756349 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.017500385060558, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 10}. Best is trial 2 with value: 1.4565592871206376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4584 | Params: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.017500385060558, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:44:29,136] Trial 13 finished with value: 1.4590448997697196 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.01697307942073733, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 2 with value: 1.4565592871206376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4590 | Params: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.01697307942073733, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:44:39,564] Trial 14 finished with value: 1.4561369382451375 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.025411336206469487, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 14 with value: 1.4561369382451375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4561 | Params: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.025411336206469487, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:44:47,188] Trial 15 finished with value: 1.4680775542499878 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.024035836090939917, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 14 with value: 1.4561369382451375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4681 | Params: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.024035836090939917, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:44:52,484] Trial 16 finished with value: 1.4602197436848174 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.055389462526104015, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 14 with value: 1.4561369382451375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4602 | Params: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.055389462526104015, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:44:58,282] Trial 17 finished with value: 1.4648038980947262 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.028884109747413903, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 14 with value: 1.4561369382451375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4648 | Params: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.028884109747413903, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:45:06,605] Trial 18 finished with value: 1.4563073800026085 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.012899313154595582, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 14 with value: 1.4561369382451375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4563 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.012899313154595582, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:45:10,390] Trial 19 finished with value: 1.490276407001659 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.013432242407412651, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 14 with value: 1.4561369382451375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4903 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.013432242407412651, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:45:13,224] Trial 20 finished with value: 1.5049484253238468 and parameters: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.02306721030808473, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 1, 'reg_alpha': 0.01, 'reg_lambda': 0}. Best is trial 14 with value: 1.4561369382451375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.5049 | Params: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.02306721030808473, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 1, 'reg_alpha': 0.01, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:45:20,743] Trial 21 finished with value: 1.4569863799042264 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.012679813627331785, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 14 with value: 1.4561369382451375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4570 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.012679813627331785, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:45:27,492] Trial 22 finished with value: 1.4769440097668027 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.013567608974180911, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 14 with value: 1.4561369382451375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4769 | Params: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.013567608974180911, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:45:32,317] Trial 23 finished with value: 1.471114073583312 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.02425271943602954, 'subsample': 0.5, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 14 with value: 1.4561369382451375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4711 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.02425271943602954, 'subsample': 0.5, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:45:46,785] Trial 24 finished with value: 1.4558998899266515 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.010588116021742285, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 24 with value: 1.4558998899266515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4559 | Params: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.010588116021742285, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:45:55,810] Trial 25 finished with value: 1.4597813947259066 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.020434649001549923, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 24 with value: 1.4558998899266515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4598 | Params: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.020434649001549923, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:46:00,148] Trial 26 finished with value: 1.4616774698438932 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.030087533885899825, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 24 with value: 1.4558998899266515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4617 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.030087533885899825, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:46:06,589] Trial 27 finished with value: 1.4845538532398022 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.014971571624812684, 'subsample': 0.5, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 24 with value: 1.4558998899266515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4846 | Params: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.014971571624812684, 'subsample': 0.5, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:46:10,683] Trial 28 finished with value: 1.535823086135266 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.01187474156315589, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 1, 'reg_alpha': 0.01, 'reg_lambda': 1}. Best is trial 24 with value: 1.4558998899266515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.5358 | Params: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.01187474156315589, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 1, 'reg_alpha': 0.01, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:46:13,458] Trial 29 finished with value: 1.5674957453727674 and parameters: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.015022107431614844, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 24 with value: 1.4558998899266515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.5675 | Params: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.015022107431614844, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:46:24,594] Trial 30 finished with value: 1.4618263297255745 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.010078506852729424, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 24 with value: 1.4558998899266515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4618 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.010078506852729424, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:46:34,990] Trial 31 finished with value: 1.4608319910106973 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.011773931340978004, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 24 with value: 1.4558998899266515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4608 | Params: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.011773931340978004, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:46:45,378] Trial 32 finished with value: 1.4572509153721147 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.014158239548029536, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 24 with value: 1.4558998899266515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4573 | Params: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.014158239548029536, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:46:58,919] Trial 33 finished with value: 1.4557181272942268 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.010207203447393065, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 33 with value: 1.4557181272942268.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4557 | Params: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.010207203447393065, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:47:12,602] Trial 34 finished with value: 1.4554308910166842 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.01005934694256169, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 34 with value: 1.4554308910166842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4554 | Params: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.01005934694256169, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:47:23,421] Trial 35 finished with value: 1.4619437113211349 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.016758334992395686, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 34 with value: 1.4554308910166842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4619 | Params: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.016758334992395686, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:47:32,440] Trial 36 finished with value: 1.458751403699054 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.019681395820535633, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 34 with value: 1.4554308910166842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4588 | Params: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.019681395820535633, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:47:44,034] Trial 37 finished with value: 1.4578046694571225 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.010413068548113536, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 34 with value: 1.4554308910166842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4578 | Params: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.010413068548113536, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:47:46,615] Trial 38 finished with value: 1.4817342968920952 and parameters: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.04639003426007396, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 1}. Best is trial 34 with value: 1.4554308910166842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4817 | Params: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.04639003426007396, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:47:49,485] Trial 39 finished with value: 1.464721041773646 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.07246497600205533, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 34 with value: 1.4554308910166842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4647 | Params: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.07246497600205533, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:47:54,316] Trial 40 finished with value: 1.5248713068097668 and parameters: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.011555402023998332, 'subsample': 0.5, 'colsample_bytree': 0.5, 'gamma': 0, 'reg_alpha': 0.01, 'reg_lambda': 10}. Best is trial 34 with value: 1.4554308910166842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.5249 | Params: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.011555402023998332, 'subsample': 0.5, 'colsample_bytree': 0.5, 'gamma': 0, 'reg_alpha': 0.01, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:48:07,379] Trial 41 finished with value: 1.458612862750738 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.012127179690345082, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 34 with value: 1.4554308910166842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4586 | Params: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.012127179690345082, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:48:21,026] Trial 42 finished with value: 1.4576334480298967 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.01004552619460906, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 34 with value: 1.4554308910166842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4576 | Params: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.01004552619460906, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:48:27,558] Trial 43 finished with value: 1.4694026289678255 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.013192161488816752, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 34 with value: 1.4554308910166842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4694 | Params: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.013192161488816752, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:48:34,763] Trial 44 finished with value: 1.4581932140018674 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.01559300343655183, 'subsample': 0.8, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 34 with value: 1.4554308910166842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4582 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.01559300343655183, 'subsample': 0.8, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:48:42,707] Trial 45 finished with value: 1.4757166128585872 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.011260813745569932, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 34 with value: 1.4554308910166842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4757 | Params: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.011260813745569932, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:48:47,665] Trial 46 finished with value: 1.4622257807519912 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.0342268355175079, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 1}. Best is trial 34 with value: 1.4554308910166842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4622 | Params: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.0342268355175079, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:48:57,630] Trial 47 finished with value: 1.4623640840713006 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.011060408400338128, 'subsample': 0.8, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 34 with value: 1.4554308910166842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4624 | Params: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.011060408400338128, 'subsample': 0.8, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:49:05,327] Trial 48 finished with value: 1.4808974672687438 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.0186810598368398, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 10}. Best is trial 34 with value: 1.4554308910166842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4809 | Params: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.0186810598368398, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:49:08,100] Trial 49 finished with value: 1.5956508595594496 and parameters: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.012607283209415822, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 34 with value: 1.4554308910166842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.5957 | Params: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.012607283209415822, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:49:12,368] Trial 50 finished with value: 1.4535520631874912 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.02685986076723651, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 50 with value: 1.4535520631874912.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4536 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.02685986076723651, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:49:16,193] Trial 51 finished with value: 1.457556861754187 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.022204921906322023, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 50 with value: 1.4535520631874912.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4576 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.022204921906322023, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:49:19,935] Trial 52 finished with value: 1.4528734263646803 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.026408026145938252, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 52 with value: 1.4528734263646803.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4529 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.026408026145938252, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:49:23,754] Trial 53 finished with value: 1.4533826066790192 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.026847861885569695, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 52 with value: 1.4528734263646803.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4534 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.026847861885569695, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:49:27,461] Trial 54 finished with value: 1.4512561374268294 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.034073069800910266, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 54 with value: 1.4512561374268294.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4513 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.034073069800910266, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:49:31,219] Trial 55 finished with value: 1.4530712723499684 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.026413110850056425, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 54 with value: 1.4512561374268294.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4531 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.026413110850056425, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:49:35,106] Trial 56 finished with value: 1.4873347681835596 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.026644000557036678, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.01, 'reg_lambda': 0}. Best is trial 54 with value: 1.4512561374268294.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4873 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.026644000557036678, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.01, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:49:39,045] Trial 57 finished with value: 1.4507166931027986 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.032876123962653735, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 57 with value: 1.4507166931027986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4507 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.032876123962653735, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:49:42,925] Trial 58 finished with value: 1.4639238666123433 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03387551654349074, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 1}. Best is trial 57 with value: 1.4507166931027986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4639 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03387551654349074, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:49:47,687] Trial 59 finished with value: 1.4566726824791347 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.028138382002564175, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 10}. Best is trial 57 with value: 1.4507166931027986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4567 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.028138382002564175, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:49:52,035] Trial 60 finished with value: 1.4517794496043226 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03731670707651523, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 57 with value: 1.4507166931027986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4518 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03731670707651523, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:49:55,678] Trial 61 finished with value: 1.4508855519863735 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.038553886025598394, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 57 with value: 1.4507166931027986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4509 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.038553886025598394, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:49:59,948] Trial 62 finished with value: 1.453331678651164 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04127783527059915, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 57 with value: 1.4507166931027986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4533 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04127783527059915, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:50:03,927] Trial 63 finished with value: 1.4512077391859222 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.041196914819901856, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 57 with value: 1.4507166931027986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4512 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.041196914819901856, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:50:07,682] Trial 64 finished with value: 1.4516844532421957 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05129871267550389, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 57 with value: 1.4507166931027986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4517 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05129871267550389, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:50:11,492] Trial 65 finished with value: 1.4504951593460433 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.049822455394210985, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 65 with value: 1.4504951593460433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4505 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.049822455394210985, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:50:15,048] Trial 66 finished with value: 1.449699516324873 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05024743309624505, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4497 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05024743309624505, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:50:17,986] Trial 67 finished with value: 1.4630883632427083 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.050510303283319194, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4631 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.050510303283319194, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:50:21,338] Trial 68 finished with value: 1.4518347118295567 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05784126213174323, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4518 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05784126213174323, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:50:24,474] Trial 69 finished with value: 1.4702008764627161 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05517236815876795, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4702 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05517236815876795, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:50:27,945] Trial 70 finished with value: 1.4695561608901924 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04658387137835004, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4696 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04658387137835004, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:50:32,936] Trial 71 finished with value: 1.4497631188201194 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.035890243574283706, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4498 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.035890243574283706, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:50:36,274] Trial 72 finished with value: 1.4523589806876611 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.06569949335641258, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4524 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.06569949335641258, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:50:40,673] Trial 73 finished with value: 1.451457015309997 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04146073386650349, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4515 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04146073386650349, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:50:44,944] Trial 74 finished with value: 1.4502642453221952 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.041035433607486474, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4503 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.041035433607486474, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:50:48,983] Trial 75 finished with value: 1.452865233355558 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.036296908612060724, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4529 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.036296908612060724, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:50:52,515] Trial 76 finished with value: 1.4554258204468524 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.045633367276488195, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4554 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.045633367276488195, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:50:56,733] Trial 77 finished with value: 1.4516056189183306 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03176577370040611, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4516 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03176577370040611, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:51:00,975] Trial 78 finished with value: 1.4552857761279687 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.039280728867557305, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4553 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.039280728867557305, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:51:04,711] Trial 79 finished with value: 1.4521999090303814 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.030948193688587183, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4522 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.030948193688587183, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:51:08,408] Trial 80 finished with value: 1.4619635593956535 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03453021160291903, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 1}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4620 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03453021160291903, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:51:11,901] Trial 81 finished with value: 1.4507896367152202 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04151047187525551, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4508 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04151047187525551, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:51:15,649] Trial 82 finished with value: 1.4515564072765768 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04369758380314742, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4516 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04369758380314742, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:51:19,856] Trial 83 finished with value: 1.451936533441914 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.039856916686896046, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4519 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.039856916686896046, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:51:24,346] Trial 84 finished with value: 1.4522997996478986 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03609007260078713, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4523 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03609007260078713, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:51:28,339] Trial 85 finished with value: 1.45297761282199 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05176592340665776, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4530 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05176592340665776, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:51:32,527] Trial 86 finished with value: 1.4855993395074119 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04870518050730822, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4856 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04870518050730822, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:51:36,907] Trial 87 finished with value: 1.4868511283494146 and parameters: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.032439337910867436, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4869 | Params: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.032439337910867436, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:51:39,937] Trial 88 finished with value: 1.479171641772811 and parameters: {'n_estimators': 50, 'max_depth': 7, 'learning_rate': 0.04345454195808882, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4792 | Params: {'n_estimators': 50, 'max_depth': 7, 'learning_rate': 0.04345454195808882, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:51:43,511] Trial 89 finished with value: 1.45213760839839 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.059345088287069116, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4521 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.059345088287069116, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:51:47,316] Trial 90 finished with value: 1.4518175679472898 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03753908381557004, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4518 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03753908381557004, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:51:50,991] Trial 91 finished with value: 1.4522187751131717 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04148210549730172, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4522 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04148210549730172, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:51:54,999] Trial 92 finished with value: 1.4513880494423221 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04138559479563364, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4514 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04138559479563364, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:51:58,640] Trial 93 finished with value: 1.4530539185628069 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03335876228452711, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4531 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03335876228452711, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:52:02,740] Trial 94 finished with value: 1.4497831364935685 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03590111182611639, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4498 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03590111182611639, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:52:06,574] Trial 95 finished with value: 1.4722653306526714 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.029620918736562928, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4723 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.029620918736562928, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:52:10,678] Trial 96 finished with value: 1.4522705745487088 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.03569415719625789, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4523 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.03569415719625789, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:52:14,989] Trial 97 finished with value: 1.4766864031796845 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03928711187354427, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4767 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03928711187354427, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:52:19,363] Trial 98 finished with value: 1.4966648906456295 and parameters: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.048402692477759475, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 1}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4967 | Params: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.048402692477759475, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:52:24,338] Trial 99 finished with value: 1.4520882718964208 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03819511088425904, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4521 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03819511088425904, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:52:29,088] Trial 100 finished with value: 1.4760172110929215 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.03512761602719098, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4760 | Params: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.03512761602719098, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:52:33,241] Trial 101 finished with value: 1.451674748840894 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.0450916101546973, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4517 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.0450916101546973, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:52:37,797] Trial 102 finished with value: 1.4516885516258216 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.0420034111881665, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4517 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.0420034111881665, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:52:42,244] Trial 103 finished with value: 1.4517903936905172 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.0534738461217027, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4518 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.0534738461217027, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:52:45,712] Trial 104 finished with value: 1.4514294599327537 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.047688121343070516, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4514 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.047688121343070516, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:52:48,300] Trial 105 finished with value: 1.481773054471056 and parameters: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.0324394384811218, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4818 | Params: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.0324394384811218, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:52:51,948] Trial 106 finished with value: 1.4497930799088343 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04421605635166873, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4498 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04421605635166873, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:52:56,031] Trial 107 finished with value: 1.465607790101871 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04442706642145294, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4656 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04442706642145294, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:53:01,133] Trial 108 finished with value: 1.450957621710106 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.030708842944679307, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4510 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.030708842944679307, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:53:05,135] Trial 109 finished with value: 1.451481259759029 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.06149841046254441, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4515 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.06149841046254441, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:53:09,933] Trial 110 finished with value: 1.4525034738915097 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.031136915636241116, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4525 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.031136915636241116, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:53:14,534] Trial 111 finished with value: 1.4521288785607513 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.028512490589324483, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4521 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.028512490589324483, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:53:18,315] Trial 112 finished with value: 1.453132052843475 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03740931162717811, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4531 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03740931162717811, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:53:21,928] Trial 113 finished with value: 1.452961967435229 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.040078153842990696, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4530 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.040078153842990696, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:53:24,478] Trial 114 finished with value: 1.4540111242180256 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.08306442699213086, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4540 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.08306442699213086, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:53:28,293] Trial 115 finished with value: 1.4743742749570494 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03351085303251488, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4744 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03351085303251488, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:53:32,359] Trial 116 finished with value: 1.45235793980101 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.029908182755175122, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4524 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.029908182755175122, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:53:35,924] Trial 117 finished with value: 1.4754980604796095 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.043067832384986765, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 66 with value: 1.449699516324873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4755 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.043067832384986765, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:53:39,848] Trial 118 finished with value: 1.449412750137552 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.0504233741513337, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4494 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.0504233741513337, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:53:43,687] Trial 119 finished with value: 1.4878196431627109 and parameters: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.05082008105430291, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4878 | Params: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.05082008105430291, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:53:48,268] Trial 120 finished with value: 1.4548126943229007 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.046617318796240224, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 10}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4548 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.046617318796240224, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:53:51,782] Trial 121 finished with value: 1.4524570041326046 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05523387621572804, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4525 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05523387621572804, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:53:55,761] Trial 122 finished with value: 1.4515488454019452 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.036583246101512756, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4515 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.036583246101512756, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:53:59,796] Trial 123 finished with value: 1.4512968171068787 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03904848729118658, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4513 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03904848729118658, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:54:03,822] Trial 124 finished with value: 1.4513299147418244 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04912461899147364, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4513 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04912461899147364, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:54:07,731] Trial 125 finished with value: 1.4728450775519681 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.03501170885976441, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4728 | Params: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.03501170885976441, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:54:10,951] Trial 126 finished with value: 1.4741910900757822 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.0453133384860753, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 1}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4742 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.0453133384860753, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:54:13,632] Trial 127 finished with value: 1.4626958649883182 and parameters: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.04042045809355041, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4627 | Params: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.04042045809355041, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:54:16,734] Trial 128 finished with value: 1.4530223044172959 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05295109742006025, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4530 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05295109742006025, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:54:20,247] Trial 129 finished with value: 1.4695111629746231 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04229082554020879, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4695 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04229082554020879, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:54:24,220] Trial 130 finished with value: 1.4504512476871543 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03280166489860903, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4505 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03280166489860903, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:54:28,456] Trial 131 finished with value: 1.4507882209777072 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03321594523430542, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4508 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03321594523430542, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:54:32,442] Trial 132 finished with value: 1.4525022786286692 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.030723533522844994, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4525 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.030723533522844994, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:54:37,383] Trial 133 finished with value: 1.451623009016704 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03730941873399254, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4516 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03730941873399254, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:54:42,264] Trial 134 finished with value: 1.4526335775079429 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03232636963207536, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4526 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03232636963207536, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:54:49,506] Trial 135 finished with value: 1.4534807190243393 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.027767471289906327, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4535 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.027767471289906327, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:54:55,398] Trial 136 finished with value: 1.4537773143093913 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.024369205563862045, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4538 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.024369205563862045, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:55:00,067] Trial 137 finished with value: 1.4755779900210408 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03534342392310723, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4756 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03534342392310723, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:55:04,143] Trial 138 finished with value: 1.4511795176164202 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.038505418662342916, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4512 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.038505418662342916, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:55:08,101] Trial 139 finished with value: 1.4725218459628502 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.03199098415472064, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4725 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.03199098415472064, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:55:10,922] Trial 140 finished with value: 1.4522942689578793 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05799902915528397, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4523 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05799902915528397, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:55:14,471] Trial 141 finished with value: 1.4508827712393135 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.038557891080143826, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4509 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.038557891080143826, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:55:18,069] Trial 142 finished with value: 1.4515184982736815 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03899978653370959, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4515 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03899978653370959, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:55:22,277] Trial 143 finished with value: 1.45274567389013 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.033595787832334516, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4527 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.033595787832334516, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:55:26,799] Trial 144 finished with value: 1.4517727658382849 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.038207555404952645, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4518 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.038207555404952645, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:55:31,037] Trial 145 finished with value: 1.4528365490059578 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04349529080216933, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4528 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04349529080216933, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:55:36,568] Trial 146 finished with value: 1.4518339726349476 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.036587424788955596, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4518 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.036587424788955596, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:55:41,707] Trial 147 finished with value: 1.4864849513116538 and parameters: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.04967674595267738, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4865 | Params: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.04967674595267738, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:55:46,476] Trial 148 finished with value: 1.4761894127359978 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.034485340136045727, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4762 | Params: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.034485340136045727, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:55:49,081] Trial 149 finished with value: 1.4863207459402077 and parameters: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.029571983455308433, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4863 | Params: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.029571983455308433, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:55:52,094] Trial 150 finished with value: 1.4759496287827207 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04592929203619458, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 1, 'reg_alpha': 0, 'reg_lambda': 1}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4759 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04592929203619458, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 1, 'reg_alpha': 0, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:55:56,078] Trial 151 finished with value: 1.450375001970391 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03974859973078734, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4504 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03974859973078734, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:55:59,696] Trial 152 finished with value: 1.452750463889861 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03967322853929416, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4528 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03967322853929416, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:56:03,403] Trial 153 finished with value: 1.450667127495198 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.036196069839726834, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4507 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.036196069839726834, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:56:06,968] Trial 154 finished with value: 1.4547797418336468 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03650346414241293, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4548 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03650346414241293, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:56:10,895] Trial 155 finished with value: 1.4508070184181914 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03353152973713574, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4508 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03353152973713574, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:56:15,096] Trial 156 finished with value: 1.4514540432238643 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.033072096194198375, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4515 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.033072096194198375, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:56:19,851] Trial 157 finished with value: 1.4554743983375815 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03516925486519672, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4555 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03516925486519672, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:56:23,698] Trial 158 finished with value: 1.4671711294605443 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04342019966375686, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4672 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04342019966375686, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:56:27,688] Trial 159 finished with value: 1.4497749494002174 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04166803360562099, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4498 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04166803360562099, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:56:31,858] Trial 160 finished with value: 1.4758434032060843 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04147673850324344, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4758 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04147673850324344, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:56:35,544] Trial 161 finished with value: 1.4528608156012446 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.047868435296783154, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4529 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.047868435296783154, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:56:40,130] Trial 162 finished with value: 1.4510938046475228 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04038961104017059, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4511 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04038961104017059, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:56:45,175] Trial 163 finished with value: 1.4513723832367917 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.0370646995609411, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4514 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.0370646995609411, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:56:49,521] Trial 164 finished with value: 1.4529532881240173 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03410004567125153, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4530 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.03410004567125153, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:56:53,859] Trial 165 finished with value: 1.4505381435237006 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04445694700436706, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4505 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04445694700436706, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:56:57,051] Trial 166 finished with value: 1.4532199595987716 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04617905261037999, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4532 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04617905261037999, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:57:00,843] Trial 167 finished with value: 1.451275286741978 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.052637246346414715, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4513 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.052637246346414715, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:57:04,480] Trial 168 finished with value: 1.454627444106291 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.043166247560501934, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4546 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.043166247560501934, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:57:08,112] Trial 169 finished with value: 1.450534738163187 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04446266989297819, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4505 | Params: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.04446266989297819, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:57:15,231] Trial 170 finished with value: 1.4496599866135387 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.048086328981629886, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4497 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.048086328981629886, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:57:18,981] Trial 171 finished with value: 1.4525773032548213 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.049407461247725604, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4526 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.049407461247725604, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:57:26,570] Trial 172 finished with value: 1.449971550614301 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0449324166693457, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4500 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0449324166693457, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:57:33,607] Trial 173 finished with value: 1.4504465056072517 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.04433570724231927, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4504 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.04433570724231927, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:57:37,087] Trial 174 finished with value: 1.4535895694215684 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.044846733161866374, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4536 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.044846733161866374, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:57:40,619] Trial 175 finished with value: 1.4527674105718025 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.04746649653590627, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4528 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.04746649653590627, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:57:43,734] Trial 176 finished with value: 1.4498618290590193 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05077341067762763, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4499 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05077341067762763, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:57:46,863] Trial 177 finished with value: 1.4504066907347084 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05589884068108709, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4504 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05589884068108709, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:57:50,222] Trial 178 finished with value: 1.5107429044175915 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.055396632460263585, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.5107 | Params: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.055396632460263585, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:57:53,588] Trial 179 finished with value: 1.45019811031153 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06083693790331845, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4502 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06083693790331845, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:57:57,044] Trial 180 finished with value: 1.4506268293229168 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.056726908708721754, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4506 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.056726908708721754, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:58:00,828] Trial 181 finished with value: 1.4494215230956555 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06397944842435904, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 118 with value: 1.449412750137552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4494 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06397944842435904, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:58:04,487] Trial 182 finished with value: 1.4486249737777714 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06494066415968587, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 182 with value: 1.4486249737777714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4486 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06494066415968587, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:58:07,916] Trial 183 finished with value: 1.4525333864490193 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0652846315541359, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 182 with value: 1.4486249737777714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4525 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0652846315541359, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:58:10,912] Trial 184 finished with value: 1.4510964238159039 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07059609596946631, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 182 with value: 1.4486249737777714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4511 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07059609596946631, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:58:14,147] Trial 185 finished with value: 1.4500481112417676 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.062243193839513704, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 182 with value: 1.4486249737777714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4500 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.062243193839513704, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:58:19,273] Trial 186 finished with value: 1.449124063144761 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.060602005378615216, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 182 with value: 1.4486249737777714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4491 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.060602005378615216, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:58:21,929] Trial 187 finished with value: 1.4781556886690044 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.06287400128164485, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 182 with value: 1.4486249737777714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4782 | Params: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.06287400128164485, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:58:25,025] Trial 188 finished with value: 1.455716511265557 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.060479293154580886, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 182 with value: 1.4486249737777714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4557 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.060479293154580886, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:58:27,628] Trial 189 finished with value: 1.4528059784176084 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07042871343611198, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 182 with value: 1.4486249737777714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4528 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07042871343611198, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:58:30,173] Trial 190 finished with value: 1.4782960420406734 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06710863515629202, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 1}. Best is trial 182 with value: 1.4486249737777714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4783 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06710863515629202, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:58:33,128] Trial 191 finished with value: 1.4529819825798538 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.059611134047050436, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 182 with value: 1.4486249737777714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4530 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.059611134047050436, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:58:36,558] Trial 192 finished with value: 1.4514196176950973 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06324134494360181, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 182 with value: 1.4486249737777714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4514 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06324134494360181, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:58:40,011] Trial 193 finished with value: 1.451043045735551 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05417882750231907, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 182 with value: 1.4486249737777714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4510 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05417882750231907, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:58:43,395] Trial 194 finished with value: 1.4482109838069877 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06702528484328307, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4482 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06702528484328307, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:58:46,935] Trial 195 finished with value: 1.4524964635590147 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06633206831871943, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4525 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06633206831871943, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:58:49,664] Trial 196 finished with value: 1.4521912265066068 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0805857315689377, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4522 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0805857315689377, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:58:52,790] Trial 197 finished with value: 1.4684099393315195 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07327757205713323, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4684 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07327757205713323, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:58:56,580] Trial 198 finished with value: 1.4781565511704802 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07486186139659057, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4782 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07486186139659057, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:58:59,780] Trial 199 finished with value: 1.452055506057082 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06306331043049394, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4521 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06306331043049394, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:59:05,332] Trial 200 finished with value: 1.452168048417636 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05752484377925339, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4522 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05752484377925339, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:59:08,470] Trial 201 finished with value: 1.4510919089313001 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0509056092989441, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4511 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0509056092989441, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:59:11,525] Trial 202 finished with value: 1.4485473833532252 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05863700867841299, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4485 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05863700867841299, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:59:14,767] Trial 203 finished with value: 1.448544288962156 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.058646520602375074, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4485 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.058646520602375074, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:59:20,397] Trial 204 finished with value: 1.450853886810632 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05852408059537937, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4509 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05852408059537937, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:59:25,024] Trial 205 finished with value: 1.450722224475988 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06873513376409254, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4507 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06873513376409254, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:59:34,022] Trial 206 finished with value: 1.4514436132262587 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06215176095620002, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4514 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06215176095620002, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:59:37,316] Trial 207 finished with value: 1.449818209519699 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06461605460059154, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4498 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06461605460059154, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:59:40,579] Trial 208 finished with value: 1.4505519579908872 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06381422367158263, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4506 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06381422367158263, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:59:44,522] Trial 209 finished with value: 1.4520978033904686 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05472021663315232, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4521 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05472021663315232, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:59:48,035] Trial 210 finished with value: 1.4528583211307333 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06579142714594255, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4529 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06579142714594255, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:59:51,415] Trial 211 finished with value: 1.4511339254266475 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06047445992626592, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4511 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06047445992626592, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:59:54,781] Trial 212 finished with value: 1.4505531634580557 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05711282554881947, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4506 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05711282554881947, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 08:59:59,461] Trial 213 finished with value: 1.453684400033313 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06811028598254111, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4537 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06811028598254111, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:00:03,779] Trial 214 finished with value: 1.4511983713618721 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05981576528694275, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4512 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05981576528694275, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:00:06,953] Trial 215 finished with value: 1.4510620265202727 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05219388327351484, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4511 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05219388327351484, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:00:11,653] Trial 216 finished with value: 1.4549813462708667 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.06143201870014452, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4550 | Params: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.06143201870014452, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:00:14,747] Trial 217 finished with value: 1.475016242961451 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07602241582287678, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4750 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07602241582287678, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:00:18,482] Trial 218 finished with value: 1.4494274118093913 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06395305197159416, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4494 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06395305197159416, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:00:22,125] Trial 219 finished with value: 1.4806839560706702 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.06447755568807743, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4807 | Params: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.06447755568807743, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:00:25,755] Trial 220 finished with value: 1.4510571080152774 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05661878921741061, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4511 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05661878921741061, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:00:28,696] Trial 221 finished with value: 1.4507271387446001 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06872035412051752, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4507 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06872035412051752, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:00:34,326] Trial 222 finished with value: 1.4499104312710869 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06129800870915757, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 194 with value: 1.4482109838069877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4499 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06129800870915757, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:00:37,400] Trial 223 finished with value: 1.4471325068550733 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06066739497037356, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4471 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06066739497037356, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:00:40,451] Trial 224 finished with value: 1.4505842957411326 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.061381382104529605, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4506 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.061381382104529605, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:00:43,206] Trial 225 finished with value: 1.447307412484195 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06473115074126883, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4473 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06473115074126883, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:00:45,709] Trial 226 finished with value: 1.4482104146168415 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06702673865603986, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4482 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06702673865603986, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:00:48,311] Trial 227 finished with value: 1.470174394103822 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.06589712931960183, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4702 | Params: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.06589712931960183, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:00:51,044] Trial 228 finished with value: 1.4661058731069367 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06447791483745456, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4661 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06447791483745456, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:00:55,911] Trial 229 finished with value: 1.458926252679422 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07123434701459687, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4589 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07123434701459687, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:00:58,857] Trial 230 finished with value: 1.4506692253388245 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05935814803318726, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4507 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05935814803318726, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:01:02,109] Trial 231 finished with value: 1.4521878819153617 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06303632759377314, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4522 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06303632759377314, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:01:05,756] Trial 232 finished with value: 1.4490548704691235 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06730123205156549, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4491 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06730123205156549, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:01:09,000] Trial 233 finished with value: 1.4535542092481857 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06783910949410502, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4536 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06783910949410502, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:01:12,346] Trial 234 finished with value: 1.4512108720242876 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0608242313440881, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4512 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0608242313440881, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:01:15,208] Trial 235 finished with value: 1.4482327682665441 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06697346599986402, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4482 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06697346599986402, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:01:18,165] Trial 236 finished with value: 1.4666211453872706 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07719706906739317, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 1}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4666 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07719706906739317, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:01:21,437] Trial 237 finished with value: 1.4700648059713708 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07120087115495295, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4701 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07120087115495295, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:01:24,223] Trial 238 finished with value: 1.450702784304621 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06879242360121107, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4507 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06879242360121107, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:01:27,029] Trial 239 finished with value: 1.4509879599849909 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06559130874006724, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4510 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06559130874006724, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:01:30,055] Trial 240 finished with value: 1.4843916746561416 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06504533140134747, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4844 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06504533140134747, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:01:32,802] Trial 241 finished with value: 1.450969698259584 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06204190675767869, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4510 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06204190675767869, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:01:35,706] Trial 242 finished with value: 1.4501219882972483 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05856101609056105, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4501 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05856101609056105, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:01:38,412] Trial 243 finished with value: 1.4514748284645358 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.057701175580763944, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4515 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.057701175580763944, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:01:41,088] Trial 244 finished with value: 1.4478469726563383 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.066903529200381, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4478 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.066903529200381, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:01:45,590] Trial 245 finished with value: 1.4526741992574417 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07244942167236901, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4527 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07244942167236901, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:01:48,494] Trial 246 finished with value: 1.4525816841823866 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.066478382333429, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4526 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.066478382333429, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:01:51,584] Trial 247 finished with value: 1.4545360899004185 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06900328975198906, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4545 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06900328975198906, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:01:54,676] Trial 248 finished with value: 1.4493836294227025 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06409756674811949, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4494 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06409756674811949, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:01:58,125] Trial 249 finished with value: 1.4493879364744242 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.064084223469803, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4494 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.064084223469803, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:02:01,011] Trial 250 finished with value: 1.4521956531848903 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06618902172244448, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4522 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06618902172244448, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:02:04,217] Trial 251 finished with value: 1.4521944024849882 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06301626350341585, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4522 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06301626350341585, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:02:07,446] Trial 252 finished with value: 1.4522087701620816 and parameters: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.07070517838419943, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4522 | Params: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.07070517838419943, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:02:10,462] Trial 253 finished with value: 1.4500845845406656 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0672142644894204, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4501 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0672142644894204, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:02:13,902] Trial 254 finished with value: 1.4534458469941 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06423419610390654, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4534 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06423419610390654, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:02:17,425] Trial 255 finished with value: 1.4591391248636232 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.07426966215402375, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4591 | Params: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.07426966215402375, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:02:21,314] Trial 256 finished with value: 1.4615124415389105 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.052314124692285094, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4615 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.052314124692285094, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:02:24,617] Trial 257 finished with value: 1.4510005874779655 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0685401763174427, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4510 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0685401763174427, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:02:30,169] Trial 258 finished with value: 1.489731444600615 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.06356181262423398, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4897 | Params: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.06356181262423398, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:02:33,092] Trial 259 finished with value: 1.4500011322760649 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.059237741491733886, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4500 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.059237741491733886, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:02:35,755] Trial 260 finished with value: 1.4676892865919597 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05514490453877227, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4677 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05514490453877227, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:02:41,139] Trial 261 finished with value: 1.4755253518501825 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.04897344813346352, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4755 | Params: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.04897344813346352, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:02:43,880] Trial 262 finished with value: 1.468142180735305 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06601074028034354, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4681 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06601074028034354, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:02:46,856] Trial 263 finished with value: 1.449267266885593 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06168573269440615, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4493 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06168573269440615, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:02:49,372] Trial 264 finished with value: 1.4665378215341158 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07122178456128, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 1}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4665 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07122178456128, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:02:51,718] Trial 265 finished with value: 1.4685185795311733 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.09921944768904044, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4685 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.09921944768904044, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:02:55,133] Trial 266 finished with value: 1.4764547107971373 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06428785652101222, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4765 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06428785652101222, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:03:01,148] Trial 267 finished with value: 1.4513187153845137 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.058522804568320264, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4513 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.058522804568320264, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:03:03,930] Trial 268 finished with value: 1.4509605297410697 and parameters: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.06839932204814628, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4510 | Params: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.06839932204814628, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:03:10,696] Trial 269 finished with value: 1.4528438329116127 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05090145415928375, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4528 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05090145415928375, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:03:16,885] Trial 270 finished with value: 1.451025131442091 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0612333206344374, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4510 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0612333206344374, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:03:20,225] Trial 271 finished with value: 1.4515391960761241 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.054090373340400996, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4515 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.054090373340400996, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:03:23,123] Trial 272 finished with value: 1.4476672219112128 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0643309120336051, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4477 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0643309120336051, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:03:29,072] Trial 273 finished with value: 1.4507362547809919 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.06436566435605556, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4507 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.06436566435605556, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:03:31,776] Trial 274 finished with value: 1.4512471948596417 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06669281676468683, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4512 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06669281676468683, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:03:34,671] Trial 275 finished with value: 1.450923585447998 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07683445316301965, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4509 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07683445316301965, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:03:38,208] Trial 276 finished with value: 1.4493554993182216 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06268350120861432, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4494 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06268350120861432, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:03:41,217] Trial 277 finished with value: 1.449485288013539 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06017822932267446, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4495 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06017822932267446, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:03:44,365] Trial 278 finished with value: 1.4670333366206418 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.059953573458634085, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4670 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.059953573458634085, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:03:48,204] Trial 279 finished with value: 1.4565257418551842 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.06257075794314913, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4565 | Params: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.06257075794314913, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:03:51,621] Trial 280 finished with value: 1.4516978432130587 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0569604394013002, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4517 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0569604394013002, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:03:54,579] Trial 281 finished with value: 1.4506699739627096 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05935563738891759, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4507 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05935563738891759, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:03:57,467] Trial 282 finished with value: 1.4733566849790654 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06998617196551944, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4734 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06998617196551944, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:04:00,350] Trial 283 finished with value: 1.4665860696701143 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06165901549676599, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 1, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4666 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06165901549676599, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 1, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:04:03,356] Trial 284 finished with value: 1.4880831180018521 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.07358800765838025, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4881 | Params: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.07358800765838025, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:04:06,760] Trial 285 finished with value: 1.4562545135560647 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.056820981703901305, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4563 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.056820981703901305, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:04:10,270] Trial 286 finished with value: 1.45329385922007 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0681886549615004, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4533 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0681886549615004, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:04:13,601] Trial 287 finished with value: 1.4521971942239216 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0630073442858364, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4522 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0630073442858364, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:04:17,010] Trial 288 finished with value: 1.468101823425225 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06646944201040167, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4681 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06646944201040167, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:04:20,305] Trial 289 finished with value: 1.495158583867906 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.05892117642900786, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4952 | Params: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.05892117642900786, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:04:23,625] Trial 290 finished with value: 1.4619193935987096 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06424795677043231, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 1}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4619 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06424795677043231, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:04:27,093] Trial 291 finished with value: 1.4512903051775778 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.061138680247261934, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4513 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.061138680247261934, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:04:29,867] Trial 292 finished with value: 1.451034039441337 and parameters: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.07196729974999355, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4510 | Params: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.07196729974999355, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:04:32,581] Trial 293 finished with value: 1.4508228245387682 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06601265918489425, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4508 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06601265918489425, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:04:38,271] Trial 294 finished with value: 1.4513880530086067 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05513974510182271, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4514 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05513974510182271, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:04:41,386] Trial 295 finished with value: 1.4499308390464447 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06145519703241967, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4499 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06145519703241967, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:04:44,336] Trial 296 finished with value: 1.4537174209778985 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.06795826322496917, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4537 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.06795826322496917, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:04:47,507] Trial 297 finished with value: 1.4514607389391057 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05773388194090279, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4515 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05773388194090279, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:04:50,556] Trial 298 finished with value: 1.4531126370146223 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.08119731588438886, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4531 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.08119731588438886, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:04:53,902] Trial 299 finished with value: 1.4513254734264016 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06373851403171307, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4513 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06373851403171307, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:04:57,221] Trial 300 finished with value: 1.4512894590282825 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0693974834669949, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4513 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0693974834669949, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:05:00,535] Trial 301 finished with value: 1.4668347984801073 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.060590757192596545, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4668 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.060590757192596545, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:05:04,050] Trial 302 finished with value: 1.4519719756551352 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.053566635914806635, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4520 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.053566635914806635, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:05:07,248] Trial 303 finished with value: 1.4535563187933305 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06519474566059862, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4536 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06519474566059862, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:05:13,115] Trial 304 finished with value: 1.4575517627456367 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.0719657196118981, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4576 | Params: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.0719657196118981, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:05:16,091] Trial 305 finished with value: 1.4584866748173901 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0592025095872931, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4585 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0592025095872931, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:05:19,069] Trial 306 finished with value: 1.4609848077792376 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06244869940301428, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4610 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06244869940301428, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:05:21,902] Trial 307 finished with value: 1.4758030250959713 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05651125961062247, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4758 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05651125961062247, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:05:24,603] Trial 308 finished with value: 1.4868111285402927 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.06634434628813994, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4868 | Params: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.06634434628813994, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:05:27,204] Trial 309 finished with value: 1.4510047819605707 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06852787591832567, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4510 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06852787591832567, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:05:29,994] Trial 310 finished with value: 1.4491148459378569 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06499763198059971, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4491 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06499763198059971, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:05:32,811] Trial 311 finished with value: 1.4672728196335756 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06365114648624381, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4673 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06365114648624381, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:05:35,404] Trial 312 finished with value: 1.4933194165753712 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.05984467530012787, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4933 | Params: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.05984467530012787, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:05:38,278] Trial 313 finished with value: 1.4510948753188724 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07060192848068962, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4511 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07060192848068962, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:05:41,578] Trial 314 finished with value: 1.451374150093097 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0754361743766818, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4514 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0754361743766818, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:05:44,825] Trial 315 finished with value: 1.4494667700034107 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06496112096752042, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4495 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06496112096752042, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:05:48,189] Trial 316 finished with value: 1.465639698935113 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06611910962423795, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 1}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4656 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06611910962423795, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:05:51,538] Trial 317 finished with value: 1.4496941441211504 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06264829384043817, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4497 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06264829384043817, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:05:54,338] Trial 318 finished with value: 1.4502594087558145 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06300745294705587, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4503 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06300745294705587, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:05:57,144] Trial 319 finished with value: 1.4530622109355618 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06829257289644441, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4531 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06829257289644441, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:05:59,812] Trial 320 finished with value: 1.4505609223204523 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06169094141889789, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4506 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06169094141889789, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:06:02,812] Trial 321 finished with value: 1.4497358363931434 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06509319114505999, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4497 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06509319114505999, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:06:05,756] Trial 322 finished with value: 1.4514515580174383 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.058342464496750984, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4515 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.058342464496750984, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:06:08,615] Trial 323 finished with value: 1.4515832081971691 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06364721405487296, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4516 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06364721405487296, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:06:11,492] Trial 324 finished with value: 1.4530533125559253 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07031642255871268, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4531 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07031642255871268, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:06:14,880] Trial 325 finished with value: 1.467680863516474 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06011653157179452, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4677 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06011653157179452, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:06:17,770] Trial 326 finished with value: 1.4534779965868134 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06755148152607725, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4535 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06755148152607725, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:06:20,646] Trial 327 finished with value: 1.4503511394917359 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07362226680211872, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4504 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07362226680211872, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:06:26,111] Trial 328 finished with value: 1.4523136336318672 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.021588838495023074, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4523 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.021588838495023074, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:06:28,916] Trial 329 finished with value: 1.5680547504908 and parameters: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.017794030685074392, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.5681 | Params: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.017794030685074392, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:06:32,360] Trial 330 finished with value: 1.4538993030494824 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05695907198815921, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4539 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05695907198815921, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:06:35,289] Trial 331 finished with value: 1.4633458693360377 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06456261819272, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4633 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06456261819272, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:06:37,929] Trial 332 finished with value: 1.4729428793477979 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07896829523693061, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 0}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4729 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07896829523693061, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:06:43,353] Trial 333 finished with value: 1.4501173460474015 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.061263601726868476, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4501 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.061263601726868476, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:06:45,941] Trial 334 finished with value: 1.5189427430271663 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.06735962623553025, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.5189 | Params: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.06735962623553025, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:06:49,050] Trial 335 finished with value: 1.4516678303456707 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05507431573717335, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4517 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05507431573717335, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:06:54,165] Trial 336 finished with value: 1.4517900330423472 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06313787948884754, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4518 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06313787948884754, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:06:59,231] Trial 337 finished with value: 1.4532404703482005 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05891395642127383, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4532 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05891395642127383, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:07:01,645] Trial 338 finished with value: 1.4889729932972535 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.07280521042655788, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4890 | Params: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.07280521042655788, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:07:04,328] Trial 339 finished with value: 1.4522363928902837 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06530303318177666, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4522 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06530303318177666, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:07:07,115] Trial 340 finished with value: 1.4532521067654511 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06983225181321573, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4533 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06983225181321573, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:07:09,954] Trial 341 finished with value: 1.4515997801910976 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06191866929736105, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4516 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06191866929736105, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:07:12,576] Trial 342 finished with value: 1.4607127128998123 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06639747021262794, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 1}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4607 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06639747021262794, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:07:15,470] Trial 343 finished with value: 1.4519845031740153 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05777193590385775, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4520 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05777193590385775, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:07:18,626] Trial 344 finished with value: 1.450241244139963 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06128131828315808, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4502 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06128131828315808, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:07:21,889] Trial 345 finished with value: 1.4514103220331063 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.054278762300468165, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4514 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.054278762300468165, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:07:24,698] Trial 346 finished with value: 1.4606736588767049 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.09011118829214348, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4607 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.09011118829214348, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:07:27,960] Trial 347 finished with value: 1.4505523728610148 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0638128848959514, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4506 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0638128848959514, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:07:31,234] Trial 348 finished with value: 1.4498797553943432 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05912845943589425, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4499 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05912845943589425, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:07:34,403] Trial 349 finished with value: 1.4506752608522657 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06716097984145508, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4507 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06716097984145508, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:07:37,304] Trial 350 finished with value: 1.4514699867804062 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0704177477215987, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4515 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0704177477215987, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:07:40,086] Trial 351 finished with value: 1.453124822758028 and parameters: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.06304580815474146, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4531 | Params: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.06304580815474146, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:07:43,178] Trial 352 finished with value: 1.4567016001493405 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.060636364680351905, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4567 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.060636364680351905, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:07:46,159] Trial 353 finished with value: 1.4630011116329567 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.06616623573570807, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4630 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.06616623573570807, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:07:49,423] Trial 354 finished with value: 1.4560175915013305 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05298501779279926, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4560 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05298501779279926, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:07:51,955] Trial 355 finished with value: 1.4503794484787225 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06946193599368493, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4504 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06946193599368493, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:07:54,687] Trial 356 finished with value: 1.4668767017702504 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0570399062902797, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4669 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0570399062902797, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:07:57,748] Trial 357 finished with value: 1.4654713394960521 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.06372073810395984, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4655 | Params: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.06372073810395984, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:08:00,277] Trial 358 finished with value: 1.493090076275856 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.07438979341355534, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4931 | Params: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.07438979341355534, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:08:03,043] Trial 359 finished with value: 1.4500535558033147 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.060180360947914985, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4501 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.060180360947914985, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:08:05,585] Trial 360 finished with value: 1.4535377337666266 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06550666703558061, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4535 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06550666703558061, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:08:08,087] Trial 361 finished with value: 1.4510141483467596 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06850043512763485, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4510 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06850043512763485, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:08:11,114] Trial 362 finished with value: 1.4479481819621356 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05709700254404589, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4479 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05709700254404589, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:08:13,976] Trial 363 finished with value: 1.4678716577876554 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.05876990988664985, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4679 | Params: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.05876990988664985, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:08:17,430] Trial 364 finished with value: 1.4493083017695447 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05607607881252289, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4493 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05607607881252289, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:08:20,931] Trial 365 finished with value: 1.44905370228127 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05518259149529152, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4491 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05518259149529152, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:08:24,948] Trial 366 finished with value: 1.4487859813521917 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05509661987863238, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4488 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05509661987863238, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:08:28,168] Trial 367 finished with value: 1.4540688301790314 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05478637704471347, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4541 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05478637704471347, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:08:33,873] Trial 368 finished with value: 1.4496241318636158 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05547265078220078, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4496 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05547265078220078, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:08:36,886] Trial 369 finished with value: 1.4633396400928274 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.052949021886625314, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4633 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.052949021886625314, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:08:42,327] Trial 370 finished with value: 1.4493214961648697 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05593157294843238, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4493 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05593157294843238, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:08:47,832] Trial 371 finished with value: 1.4536374155690668 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05217544649576851, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4536 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05217544649576851, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:08:50,781] Trial 372 finished with value: 1.45132246144574 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05584435515812181, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4513 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05584435515812181, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:08:56,246] Trial 373 finished with value: 1.4549487682468403 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.056595408594712196, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4549 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.056595408594712196, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:08:59,329] Trial 374 finished with value: 1.4479225487478085 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05704588856171864, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4479 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05704588856171864, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:09:05,519] Trial 375 finished with value: 1.4504525661231145 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05563846229204322, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4505 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05563846229204322, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:09:08,423] Trial 376 finished with value: 1.458280234476946 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05108488298559152, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4583 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05108488298559152, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:09:13,758] Trial 377 finished with value: 1.4514285217871123 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05743867704854711, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4514 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05743867704854711, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:09:17,586] Trial 378 finished with value: 1.4620775727175925 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.053107402362570326, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4621 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.053107402362570326, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:09:21,166] Trial 379 finished with value: 1.4526642353512815 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05763289981724739, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4527 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05763289981724739, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:09:23,961] Trial 380 finished with value: 1.4796021283378809 and parameters: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.053619257739968576, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4796 | Params: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.053619257739968576, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:09:26,816] Trial 381 finished with value: 1.4514663198574647 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05857619070256993, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4515 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05857619070256993, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:09:29,936] Trial 382 finished with value: 1.476342048750986 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05669923877494679, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4763 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05669923877494679, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:09:35,519] Trial 383 finished with value: 1.4500976300252153 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05492915683201852, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4501 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05492915683201852, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:09:38,421] Trial 384 finished with value: 1.4475678694713676 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.0593003975324243, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4476 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.0593003975324243, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:09:43,382] Trial 385 finished with value: 1.4754948953816456 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.059522897668145044, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4755 | Params: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.059522897668145044, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:09:49,506] Trial 386 finished with value: 1.451255309971619 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05486256254357706, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4513 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05486256254357706, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:09:52,684] Trial 387 finished with value: 1.4536741015481296 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06007149533562984, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4537 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06007149533562984, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:09:56,026] Trial 388 finished with value: 1.451969811171263 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05738032430998059, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4520 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05738032430998059, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:10:01,117] Trial 389 finished with value: 1.4521656489246835 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.08588106887592267, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4522 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.08588106887592267, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:10:04,402] Trial 390 finished with value: 1.4692908683002823 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.05175127220119132, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4693 | Params: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.05175127220119132, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:10:07,447] Trial 391 finished with value: 1.4505000708265616 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.06117981585723509, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4505 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.06117981585723509, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:10:10,766] Trial 392 finished with value: 1.4506087333418918 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.058158303956915035, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4506 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.058158303956915035, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:10:13,687] Trial 393 finished with value: 1.463284113768094 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06068675049566404, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4633 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06068675049566404, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:10:16,952] Trial 394 finished with value: 1.4536701652661634 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05369591981476425, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4537 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05369591981476425, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:10:20,262] Trial 395 finished with value: 1.4490237210377561 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.055247934175908585, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 223 with value: 1.4471325068550733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4490 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.055247934175908585, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:10:23,653] Trial 396 finished with value: 1.445510838816704 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05610174788189348, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4455 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05610174788189348, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:10:26,734] Trial 397 finished with value: 1.4501397562560574 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05641636722210238, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4501 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05641636722210238, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:10:32,824] Trial 398 finished with value: 1.45363849291582 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05458292337433711, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4536 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05458292337433711, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:10:36,043] Trial 399 finished with value: 1.4494190602484787 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05805081799200497, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4494 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05805081799200497, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:10:39,692] Trial 400 finished with value: 1.4643729249985293 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.050735383203665774, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4644 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.050735383203665774, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:10:43,196] Trial 401 finished with value: 1.4547463074422644 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.0563571581695181, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4547 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.0563571581695181, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:10:46,886] Trial 402 finished with value: 1.4520454956700717 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05304636917165897, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4520 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05304636917165897, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:10:50,664] Trial 403 finished with value: 1.4522960567246228 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.06096678332905444, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4523 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.06096678332905444, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:10:53,922] Trial 404 finished with value: 1.4522741662771892 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.061018283130862834, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4523 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.061018283130862834, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:10:58,730] Trial 405 finished with value: 1.4627767150476065 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.05844791587198024, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4628 | Params: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.05844791587198024, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:11:04,189] Trial 406 finished with value: 1.452125966111649 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07259925316665168, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4521 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07259925316665168, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:11:07,976] Trial 407 finished with value: 1.4773253652918088 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05617412851941687, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4773 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05617412851941687, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:11:14,076] Trial 408 finished with value: 1.448511563542614 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0619752311947806, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4485 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0619752311947806, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:11:17,586] Trial 409 finished with value: 1.4562529753585904 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05277240098847867, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4563 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05277240098847867, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:11:20,769] Trial 410 finished with value: 1.450326096288375 and parameters: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.0617739374085589, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4503 | Params: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.0617739374085589, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:11:27,470] Trial 411 finished with value: 1.4735576514222557 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.05853252746257354, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4736 | Params: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.05853252746257354, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:11:37,337] Trial 412 finished with value: 1.4522370036358685 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.014745118796814281, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4522 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.014745118796814281, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:11:45,091] Trial 413 finished with value: 1.4538802479185216 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.054612993716795996, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4539 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.054612993716795996, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:11:48,933] Trial 414 finished with value: 1.4506187702259008 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.04995054080493457, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4506 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.04995054080493457, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:11:54,252] Trial 415 finished with value: 1.4692130612196643 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.06193516729939428, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4692 | Params: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.06193516729939428, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:11:59,210] Trial 416 finished with value: 1.467058482637415 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0675695760292945, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4671 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0675695760292945, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:12:03,011] Trial 417 finished with value: 1.449906292753693 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0589148060567793, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4499 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0589148060567793, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:12:10,505] Trial 418 finished with value: 1.4501463907525602 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05565633634353636, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4501 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05565633634353636, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:12:16,967] Trial 419 finished with value: 1.45152491090051 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06298268808541076, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4515 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06298268808541076, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:12:25,063] Trial 420 finished with value: 1.450553285887588 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.059915299995671724, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4506 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.059915299995671724, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:12:32,054] Trial 421 finished with value: 1.450280049966116 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06750774283189605, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4503 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06750774283189605, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:12:38,155] Trial 422 finished with value: 1.4587745898710198 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.07619982556543727, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4588 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.07619982556543727, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:12:41,542] Trial 423 finished with value: 1.4599010508545804 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0713138065006702, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4599 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0713138065006702, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:12:45,717] Trial 424 finished with value: 1.4495529943756085 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.056933510824258834, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4496 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.056933510824258834, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:12:53,841] Trial 425 finished with value: 1.4567125410533952 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06503195413640134, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4567 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06503195413640134, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:12:58,196] Trial 426 finished with value: 1.455484493343007 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.053576681125764684, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4555 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.053576681125764684, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:13:02,200] Trial 427 finished with value: 1.4516882354389586 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06277951292152854, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4517 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06277951292152854, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:13:06,962] Trial 428 finished with value: 1.4877998648951085 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06035026992086517, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4878 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06035026992086517, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:13:10,825] Trial 429 finished with value: 1.4622884418327586 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.056811172135308514, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 1}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4623 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.056811172135308514, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:13:20,250] Trial 430 finished with value: 1.4563633109224192 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.06640282505277743, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4564 | Params: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.06640282505277743, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:13:28,140] Trial 431 finished with value: 1.4574364340582584 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.051609536259694486, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4574 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.051609536259694486, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:13:32,410] Trial 432 finished with value: 1.451766174232823 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.06958617980702332, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4518 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.06958617980702332, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:13:36,680] Trial 433 finished with value: 1.449323083038133 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05844914520467771, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4493 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05844914520467771, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:13:39,992] Trial 434 finished with value: 1.4510514615912753 and parameters: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.05560938544114169, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4511 | Params: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.05560938544114169, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:13:44,950] Trial 435 finished with value: 1.454593286545911 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05398168486375688, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4546 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05398168486375688, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:13:48,871] Trial 436 finished with value: 1.453264151349466 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05752847218197572, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4533 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05752847218197572, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:13:52,692] Trial 437 finished with value: 1.4498698986791048 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05914782676048638, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4499 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05914782676048638, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:13:59,016] Trial 438 finished with value: 1.474980800131752 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.05955711878126864, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4750 | Params: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.05955711878126864, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:14:03,648] Trial 439 finished with value: 1.4629423000886521 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.051882093388464674, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4629 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.051882093388464674, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:14:14,633] Trial 440 finished with value: 1.4528396563022503 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.02531269410657616, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4528 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.02531269410657616, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:14:19,431] Trial 441 finished with value: 1.4950308735357405 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.06238967898122463, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4950 | Params: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.06238967898122463, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:14:28,582] Trial 442 finished with value: 1.4494929742279334 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.055069415841011, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4495 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.055069415841011, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:14:35,739] Trial 443 finished with value: 1.4547532948481108 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06625884228767476, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4548 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06625884228767476, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:14:43,715] Trial 444 finished with value: 1.4567294585167183 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.04898031537713186, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4567 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.04898031537713186, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:14:46,989] Trial 445 finished with value: 1.4514563529996007 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05860222921567126, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4515 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05860222921567126, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:14:49,808] Trial 446 finished with value: 1.4632165182176735 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06166195293308549, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4632 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06166195293308549, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:14:52,880] Trial 447 finished with value: 1.4629542728070537 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07231633122427622, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 1}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4630 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07231633122427622, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:14:58,919] Trial 448 finished with value: 1.4495115251417678 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0645113567966594, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4495 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0645113567966594, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:15:02,616] Trial 449 finished with value: 1.4660339663809407 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05695327277613553, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4660 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05695327277613553, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:15:10,071] Trial 450 finished with value: 1.45159745998315 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05366043681161196, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4516 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05366043681161196, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:15:14,742] Trial 451 finished with value: 1.4767585624915733 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05977256107891094, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4768 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05977256107891094, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:15:20,522] Trial 452 finished with value: 1.455644572642415 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06721621286781226, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4556 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06721621286781226, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:15:23,682] Trial 453 finished with value: 1.4684624419873225 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.056504140239912896, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4685 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.056504140239912896, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:15:27,267] Trial 454 finished with value: 1.452493556972539 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.062386493870685365, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4525 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.062386493870685365, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:15:33,128] Trial 455 finished with value: 1.4518646962687471 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07008686018905406, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4519 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07008686018905406, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:15:39,114] Trial 456 finished with value: 1.4519057731118044 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05986009574377138, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4519 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05986009574377138, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:15:42,130] Trial 457 finished with value: 1.46868885269854 and parameters: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.06453171133794924, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4687 | Params: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.06453171133794924, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:15:48,062] Trial 458 finished with value: 1.4520993895269423 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05131947824394981, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4521 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05131947824394981, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:15:51,040] Trial 459 finished with value: 1.4628739259431738 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05501673019108565, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 1}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4629 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05501673019108565, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:15:54,224] Trial 460 finished with value: 1.4493548685428093 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0769614084388725, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4494 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0769614084388725, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:15:58,237] Trial 461 finished with value: 1.473646791882137 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.058095241526096845, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4736 | Params: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.058095241526096845, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:16:05,286] Trial 462 finished with value: 1.4516330967909619 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06208222934146472, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4516 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06208222934146472, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:16:10,964] Trial 463 finished with value: 1.4507832042129623 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06671651155072618, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4508 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06671651155072618, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:16:14,472] Trial 464 finished with value: 1.4502916751465407 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06448562720456956, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4503 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06448562720456956, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:16:20,478] Trial 465 finished with value: 1.4509825430556345 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06895058619769512, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4510 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06895058619769512, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:16:24,629] Trial 466 finished with value: 1.4573629930498169 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06035892412539741, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4574 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06035892412539741, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:16:27,729] Trial 467 finished with value: 1.4815293605735163 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.0529190185056214, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4815 | Params: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.0529190185056214, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:16:34,022] Trial 468 finished with value: 1.4559798880753039 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05674980553531437, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4560 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05674980553531437, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:16:36,701] Trial 469 finished with value: 1.472899018373359 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07285026826648429, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4729 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.07285026826648429, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:16:42,139] Trial 470 finished with value: 1.4487156006836568 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06307881961835259, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4487 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06307881961835259, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:16:45,772] Trial 471 finished with value: 1.4823089665356979 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06477893255486847, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 1}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4823 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06477893255486847, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:16:52,412] Trial 472 finished with value: 1.4529560281631686 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06883704203426311, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4530 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06883704203426311, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:16:56,809] Trial 473 finished with value: 1.48065799735335 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06310653946659188, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4807 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06310653946659188, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:17:00,773] Trial 474 finished with value: 1.45382062689549 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06617367675080246, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4538 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06617367675080246, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:17:08,189] Trial 475 finished with value: 1.4513908993296365 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.061211405093599985, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4514 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.061211405093599985, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:17:11,450] Trial 476 finished with value: 1.4536188391959282 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.0709265462999725, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4536 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.0709265462999725, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:17:16,992] Trial 477 finished with value: 1.4541295533515939 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06225452909976241, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4541 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06225452909976241, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:17:20,013] Trial 478 finished with value: 1.470579045002664 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06627741176878442, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4706 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06627741176878442, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:17:26,706] Trial 479 finished with value: 1.453053732103693 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05466629869140865, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4531 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05466629869140865, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:17:28,979] Trial 480 finished with value: 1.4542115680575527 and parameters: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.05898422553583617, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4542 | Params: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.05898422553583617, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:17:32,771] Trial 481 finished with value: 1.4541857132107334 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.06404895500619666, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4542 | Params: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.06404895500619666, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:17:41,240] Trial 482 finished with value: 1.45145361077635 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.016231944521742144, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4515 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.016231944521742144, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:17:45,239] Trial 483 finished with value: 1.4640299857286112 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.04840533393501094, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4640 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.04840533393501094, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:17:48,083] Trial 484 finished with value: 1.4949173948779606 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.06858738435918763, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 1}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4949 | Params: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.06858738435918763, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 1, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:17:53,990] Trial 485 finished with value: 1.4547826353361604 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0607386501712778, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4548 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0607386501712778, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:17:57,499] Trial 486 finished with value: 1.4528068297628527 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05684677925687849, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4528 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05684677925687849, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:18:00,865] Trial 487 finished with value: 1.4517444002958724 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06266259367540343, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4517 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06266259367540343, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:18:05,721] Trial 488 finished with value: 1.4649923946724583 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.07284411546338015, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4650 | Params: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.07284411546338015, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:18:09,634] Trial 489 finished with value: 1.4597154936359646 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.050294792075747274, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4597 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.050294792075747274, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 1, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:18:15,668] Trial 490 finished with value: 1.455959134606948 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05907975320118837, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4560 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05907975320118837, 'subsample': 1.0, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:18:21,771] Trial 491 finished with value: 1.449665972908856 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.055355300181058296, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4497 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.055355300181058296, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:18:24,588] Trial 492 finished with value: 1.470043217175489 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06681212266024794, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4700 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06681212266024794, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 0, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:18:27,242] Trial 493 finished with value: 1.4677408781171262 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06460443909245984, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4677 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06460443909245984, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:18:32,963] Trial 494 finished with value: 1.453464783101285 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05293209912100084, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4535 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05293209912100084, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:18:35,383] Trial 495 finished with value: 1.4811715074667573 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.07569568016861133, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4812 | Params: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.07569568016861133, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:18:40,718] Trial 496 finished with value: 1.4547931833190149 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0607096427346496, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4548 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.0607096427346496, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:18:43,437] Trial 497 finished with value: 1.4519268212507959 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06969794718520263, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4519 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06969794718520263, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:18:46,908] Trial 498 finished with value: 1.4495670917893069 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05594760879724491, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4496 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05594760879724491, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 5, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-08 09:18:50,207] Trial 499 finished with value: 1.449331954588594 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05842984376557989, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10}. Best is trial 396 with value: 1.445510838816704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial RMSE: 1.4493 | Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05842984376557989, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0.1, 'reg_lambda': 10, 'random_state': 42, 'early_stopping_rounds': 20, 'eval_metric': 'rmse'}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [50, 100, 300, 500]),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [3, 5, 7, 10]),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.5, 0.8, 1.0]),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.5, 0.8, 1.0]),\n",
    "        'gamma': trial.suggest_categorical('gamma', [0, 1, 5]),\n",
    "        'reg_alpha': trial.suggest_categorical('reg_alpha', [0, 0.01, 0.1]),\n",
    "        'reg_lambda': trial.suggest_categorical('reg_lambda', [0, 1, 5, 10]),\n",
    "        'random_state': 42,\n",
    "        'early_stopping_rounds': 20,\n",
    "        'eval_metric': 'rmse'\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train, \n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "        )\n",
    "\n",
    "    preds = model.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, preds) ** 0.5\n",
    "    print(f\"Trial RMSE: {rmse:.4f} | Params: {params}\")\n",
    "    return rmse\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=500)  # n_trials: 탐색 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4937d637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  RMSE: 1.445510838816704\n",
      "  Params: \n",
      "    n_estimators: 500\n",
      "    max_depth: 5\n",
      "    learning_rate: 0.05610174788189348\n",
      "    subsample: 1.0\n",
      "    colsample_bytree: 1.0\n",
      "    gamma: 5\n",
      "    reg_alpha: 0.1\n",
      "    reg_lambda: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=5, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.05610174788189348, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "             num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;reg:squarederror&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.05610174788189348</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">500</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=5, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.05610174788189348, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "             num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"  RMSE: {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# 최적 하이퍼파라미터로 모델 재학습\n",
    "best_params = trial.params\n",
    "best_model = XGBRegressor(**best_params)\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c4ed09",
   "metadata": {},
   "source": [
    "#### re-train with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cf2848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=5, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.05610174788189348, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "             num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;reg:squarederror&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.05610174788189348</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">500</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=5, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.05610174788189348, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "             num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_params는 베이지안 최적화가 반환한 파라미터 dict\n",
    "best_params = {\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.05610174788189348,\n",
    "    'subsample': 1.0,\n",
    "    'colsample_bytree': 1.0,\n",
    "    'gamma': 5,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 10,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# train + val 합치기\n",
    "X_train_val = pd.concat([X_train, X_val], axis=0)\n",
    "y_train_val = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "# 같은 하이퍼파라미터로 모델 초기화 및 재학습\n",
    "model_final = XGBRegressor(**best_params)\n",
    "model_final.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780b09bd",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "697ad585",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"C:/Users/user/Desktop/dacon_drug_development/dataset/test.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f801694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n",
      "[09:31:26] DEPRECATION WARNING: please use MorganGenerator\n"
     ]
    }
   ],
   "source": [
    "test['Fingerprint'] = test['Smiles'].apply(smiles_to_fingerprint)\n",
    "test = test[test['Fingerprint'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "55eaa716",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_df = pd.DataFrame([descriptors(s) for s in test['Smiles']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fdab078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_dataset = pd.concat([test, test_features_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e61b5a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_df = pd.DataFrame(test_final_dataset['Fingerprint'].tolist(), index=test_final_dataset.index)\n",
    "fp_df.columns = [f'fp_{i}' for i in range(fp_df.shape[1])]\n",
    "test_final_dataset = pd.concat(\n",
    "    [test_final_dataset.drop(columns=['Fingerprint']), fp_df],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7c8fcf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_final_dataset.drop(['ID', 'Smiles'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "af8c1ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pIC50_pred'] = model_final.predict(X_test)\n",
    "test['ASK1_IC50_nM'] = pIC50_to_IC50(test['pIC50_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09173c87",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8e94304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('C:/Users/user/Desktop/dacon_drug_development/sample_submission.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ce64d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['ASK1_IC50_nM'] = test['ASK1_IC50_nM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c9e19dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"XGBRegressor_1_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
